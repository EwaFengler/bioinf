{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implementacja algorytmu mrówkowego.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "import re\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BASE_DIR_PATH = path.dirname(path.abspath(\"__file__\"))  # gdyby nie działało, usuń cudzysłów\n",
    "INSTANCES_PATH = path.join(BASE_DIR_PATH, \"instances\")\n",
    "NEGATIVE_RANDOM_PATH = path.join(INSTANCES_PATH, \"negative_random\")\n",
    "NEGATIVE_REPETITIONS_PATH = path.join(INSTANCES_PATH, \"negative_repetitions\")\n",
    "POSITIVE_END_ERRORS_PATH = path.join(INSTANCES_PATH, \"positive_end_errors\")\n",
    "POSITIVE_RANDOM_PATH = path.join(INSTANCES_PATH, \"positive_random\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "negative_random_filenames = [path.join(NEGATIVE_RANDOM_PATH, f) for f in listdir(NEGATIVE_RANDOM_PATH) if path.isfile(path.join(NEGATIVE_RANDOM_PATH, f))]\n",
    "negative_repetitions_filenames = [path.join(NEGATIVE_REPETITIONS_PATH, f) for f in listdir(NEGATIVE_REPETITIONS_PATH) if path.isfile(path.join(NEGATIVE_REPETITIONS_PATH, f))]\n",
    "positive_end_errors_filenames = [path.join(POSITIVE_END_ERRORS_PATH, f) for f in listdir(POSITIVE_END_ERRORS_PATH) if path.isfile(path.join(POSITIVE_END_ERRORS_PATH, f))]\n",
    "positive_random_filenames = [path.join(POSITIVE_RANDOM_PATH, f) for f in listdir(POSITIVE_RANDOM_PATH) if path.isfile(path.join(POSITIVE_RANDOM_PATH, f))]\n",
    "\n",
    "selected_filenames = negative_random_filenames + negative_repetitions_filenames + positive_end_errors_filenames + positive_random_filenames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ProblemPropertiesClass:\n",
    "    def __init__(self):\n",
    "        self.words = []\n",
    "        self.word_len = 0\n",
    "        self.org_seq_len = 0\n",
    "        self.words_num = 0\n",
    "        \n",
    "        self.common_nucleotides_matrix = np.zeros((self.words_num + 1, self.words_num + 1), dtype=int)\n",
    "        self.wages = np.zeros(self.word_len)\n",
    "        self.next_word_power_matrix = np.zeros((self.words_num + 1, self.words_num + 1))\n",
    "        \n",
    "        self.sequences = []\n",
    "        self.best_sequence = []\n",
    "        self.best_sequence_len = 0\n",
    "        self.sequences_lengths_of_all_iterations = []\n",
    "        \n",
    "        self.avaible_words = np.ones(self.words_num + 1, dtype=bool)\n",
    "        self.avaible_words_number = self.words_num\n",
    "        self.current_word = 0\n",
    "        self.current_length = 0\n",
    "        self.sequence = []\n",
    "        \n",
    "        self.iteration_with_the_best_sequence = 0\n",
    "        self.iterations_number_limit = 30\n",
    "        \n",
    "        #parametry algorytmu\n",
    "        self.iterations_number = 100\n",
    "        self.attempts_number = 100\n",
    "        self.part_of_the_best_sequences = 0.1\n",
    "        self.best_price_for_sequence = 1.2\n",
    "        self.k_set_starting_wages = 2\n",
    "        self.compensation_coef = 0.98\n",
    "        self.base_of_logarithm = 2\n",
    "    \n",
    "    \n",
    "    def set_instance_info(self, words=[], word_len=0, org_seq_len=0, words_num=0):\n",
    "        self.words = words[:]\n",
    "        self.word_len = word_len\n",
    "        self.org_seq_len = org_seq_len\n",
    "        self.words_num = words_num\n",
    "        \n",
    "        self.common_nucleotides_matrix = np.zeros((self.words_num + 1, self.words_num + 1), dtype=int)\n",
    "        self.wages = np.zeros(self.word_len)\n",
    "        self.next_word_power_matrix = np.zeros((self.words_num + 1, self.words_num + 1))\n",
    "        \n",
    "        self.avaible_words = np.ones(self.words_num + 1, dtype=bool)\n",
    "        self.avaible_words_number = self.words_num\n",
    "        self.current_word = 0\n",
    "        self.current_length = 0\n",
    "        self.sequence = []\n",
    "    \n",
    "    def prepare_general_vars(self):\n",
    "        self.common_nucleotides_matrix = np.zeros((self.words_num + 1, self.words_num + 1), dtype=int)\n",
    "        self.wages = np.zeros(self.word_len)\n",
    "        self.next_word_power_matrix = np.zeros((self.words_num + 1, self.words_num + 1))\n",
    "        self.best_sequence = []\n",
    "        self.sequences_lengths_of_all_iterations = []\n",
    "        self.iteration_with_the_best_sequence = 0\n",
    "        \n",
    "    def prepare_iterations_vars(self):\n",
    "        self.sequences = []\n",
    "    \n",
    "    def prepare_attempts_vars(self):\n",
    "        self.avaible_words = np.ones(self.words_num + 1, dtype=bool)    #definicja wektora określającego, czy i-ty wyraz jest dostępny\n",
    "        self.avaible_words_number = self.words_num                      #definicja zmiennej zawierającej liczbę niewykorzystanych jeszcze wyrazów\n",
    "        self.current_word = 0                                           #definicja zmiennej wskazującej ostatnio wybranego słowa -> słowo zerowe, czyli zaczynane jest tworzenie sekwencji\n",
    "        self.current_length = 0                                         #definicja zmiennej zawierającej długość utworzonej dotychczas sekwencji\n",
    "        self.sequence = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#funkcja zwraca maksymalną liczbę nukleotydów, na których zazębia się sufiks nucl1 z prefiksem nucl2\n",
    "#poszukiwanie poprzez coraz to mniejszą długość ciągu, porównywanie ciągów znak po znaku\n",
    "def common_nucleotides_max_number_full_iterating(nucl1, nucl2):\n",
    "    word_len = len(nucl1)\n",
    "    result = word_len - 1       #zmienna zawierająca końcowy wynik\n",
    "    \n",
    "    while(result > 0):          #badanie coraz to mniejszej możliwej długości wspólnego ciągu\n",
    "        i1 = word_len - result\n",
    "        i2 = 0\n",
    "        \n",
    "        while(i1 < word_len):              #porównanie nachodzących końcówek, znak po znaku\n",
    "            if(nucl1[i1] != nucl2[i2]):    #znaki się nie zgadzają\n",
    "                break\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "        \n",
    "        if(i1 == word_len):    #porównywanie ciągów zostało wykonane pozytywnie po wszystkich znakach\n",
    "            break\n",
    "        \n",
    "        result -= 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "#funkcja zwraca maksymalną liczbę nukleotydów, na których zazębia się sufiks nucl1 z prefiksem nucl2\n",
    "#poszukiwanie poprzez coraz to mniejszą długość ciągu, bezpośrednie porównywanie ciągów przy pomocy mechanizmu \"slicing\"\n",
    "def common_nucleotides_max_number_iterating_with_slicing(nucl1, nucl2):\n",
    "    word_len = len(nucl1)\n",
    "    result = word_len - 1       #zmienna zawierająca końcowy wynik\n",
    "    \n",
    "    while(result > 0):          #badanie coraz to mniejszej możliwej długości wspólnego ciągu\n",
    "        i1 = word_len - result\n",
    "        i2 = 0\n",
    "        \n",
    "        if(nucl1[-result:] == nucl2[:result]): #porównywanie ciągów przy pomocy mechanizmu \"slicing\"\n",
    "            break\n",
    "        \n",
    "        result -= 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_common_nucleotides_matrix_full_iterating(problem_properties):\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "            for j in range(1, problem_properties.words_num + 1):\n",
    "                if(i != j):\n",
    "                    problem_properties.common_nucleotides_matrix[i, j] = common_nucleotides_max_number_full_iterating(problem_properties.words[i], problem_properties.words[j])\n",
    "                else:\n",
    "                    problem_properties.common_nucleotides_matrix[i, i] = 0\n",
    "\n",
    "def generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number(problem_properties, i, j):\n",
    "    if(i != j):\n",
    "        return common_nucleotides_max_number_full_iterating(problem_properties.words[i], problem_properties.words[j])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def generate_common_nucleotides_matrix_with_numpy_tricks(problem_properties):\n",
    "    index_of_column = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1), dtype=int)\n",
    "    index_of_row = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1), dtype=int)\n",
    "\n",
    "    index_of_column[:] = np.arange(problem_properties.words_num + 1)\n",
    "    index_of_row = index_of_column.transpose()\n",
    "\n",
    "    vectorized_generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number = np.vectorize(generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number)\n",
    "    problem_properties.common_nucleotides_matrix[1:, 1:] = vectorized_generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number(problem_properties, index_of_row[1:, 1:], index_of_column[1:, 1:])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def set_starting_wages(n, k):\n",
    "    result = np.zeros(n)\n",
    "    n -= 1\n",
    "    result[n] = 1.0\n",
    "    while(n > 0):\n",
    "        n -= 1\n",
    "        result[n] = result[n + 1] / k\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#waga przyznawana jest na podstawie długości wspólnego sufiksu-prefiksu słowa i-tego i j-tego\n",
    "def generate_next_word_power_matrix_1_full_iterating(problem_properties):\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            problem_properties.next_word_power_matrix[i, j] = problem_properties.wages[ problem_properties.common_nucleotides_matrix[i, j] ]\n",
    "            \n",
    "            \n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#waga przyznawana jest na podstawie długości wspólnego sufiksu-prefiksu słowa i-tego i j-tego\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties):\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    problem_properties.next_word_power_matrix[1:, 1:] = problem_properties.wages[ problem_properties.common_nucleotides_matrix[1:, 1:] ]\n",
    "\n",
    "    \n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "def generate_next_word_power_matrix_2_full_iterating(problem_properties):\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            occurrence_counter[ problem_properties.common_nucleotides_matrix[i, j] ] += 1\n",
    "        \n",
    "        #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "        current_wages = np.copy(problem_properties.wages)\n",
    "        for j in range(problem_properties.word_len):\n",
    "            if(occurrence_counter[j] != 0):\n",
    "                current_wages[j] /= occurrence_counter[j]\n",
    "        \n",
    "        #przydzielenie wag dla konkretnych połączeń wyrazów\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            problem_properties.next_word_power_matrix[i, j] = current_wages[ problem_properties.common_nucleotides_matrix[i, j] ]\n",
    "\n",
    "            \n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_2_with_numpy_tricks_1(problem_properties):\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "        unique, counts = np.unique(problem_properties.common_nucleotides_matrix[i, 1:], return_counts=True)\n",
    "        occurrence_counter[unique] = counts\n",
    "        \n",
    "        #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "        current_wages = np.copy(problem_properties.wages)\n",
    "        occurrence_counter[occurrence_counter == 0] = 1\n",
    "        current_wages /= occurrence_counter\n",
    "        \n",
    "        #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "        problem_properties.next_word_power_matrix[i, 1:] = current_wages[ problem_properties.common_nucleotides_matrix[i, 1:] ]\n",
    "\n",
    "            \n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties):\n",
    "    occurrence_counter = np.zeros((problem_properties.words_num + 1, problem_properties.word_len))\n",
    "    \n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        unique, counts = np.unique(problem_properties.common_nucleotides_matrix[i, 1:], return_counts=True)\n",
    "        occurrence_counter[i, unique] = counts\n",
    "        \n",
    "    occurrence_counter[occurrence_counter == 0] = 1\n",
    "        \n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.zeros((problem_properties.words_num+1, problem_properties.word_len))\n",
    "    current_wages[:] = problem_properties.wages\n",
    "    current_wages /= occurrence_counter\n",
    "    \n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        problem_properties.next_word_power_matrix[i, 1:] = current_wages[i, problem_properties.common_nucleotides_matrix[i, 1:] ]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#funkcja ustawia równe szanse wyboru słowa rozpoczynającego sekwencje\n",
    "def generate_chance_for_first_word(problem_properties):\n",
    "    problem_properties.next_word_power_matrix[0, 1:] = 1;\n",
    "\n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "def generate_chance_for_first_word_1_full_iterating(problem_properties):\n",
    "    max_common_nucleotides = np.zeros(problem_properties.words_num + 1, dtype=int)\n",
    "\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[1, j]\n",
    "        for i in range(2, problem_properties.words_num + 1):\n",
    "            if(max_common_nucleotides[j] < problem_properties.common_nucleotides_matrix[i, j]):\n",
    "                max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[i, j]\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        problem_properties.next_word_power_matrix[0, j] = problem_properties.wages[ problem_properties.word_len - 1 - max_common_nucleotides[j] ]\n",
    "\n",
    "        \n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_chance_for_first_word_1_with_numpy_tricks(problem_properties):\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    max_common_nucleotides = problem_properties.common_nucleotides_matrix.max(0)\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    problem_properties.next_word_power_matrix[0] = problem_properties.wages[ problem_properties.word_len - 1 - max_common_nucleotides]\n",
    "    \n",
    "    \n",
    "\n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#określona już waga jest równomiernie rozdzielona na wyrazy o poszczególnej długości maksymalnego zazębienia\n",
    "def generate_chance_for_first_word_2_full_iterating(problem_properties):\n",
    "    max_common_nucleotides = np.zeros(problem_properties.words_num + 1, dtype=int)\n",
    "\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[1, j]\n",
    "        for i in range(2, problem_properties.words_num + 1):\n",
    "            if(max_common_nucleotides[j] < problem_properties.common_nucleotides_matrix[i, j]):\n",
    "                max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[i, j]\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag, waga jest równomiernie rozdizelona\n",
    "    occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        occurrence_counter[ max_common_nucleotides[j] ] += 1\n",
    "\n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.flip(np.copy(problem_properties.wages))\n",
    "    for j in range(problem_properties.word_len):\n",
    "        if(occurrence_counter[j] != 0):\n",
    "            current_wages[j] /= occurrence_counter[j]\n",
    "\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        problem_properties.next_word_power_matrix[0, j] = current_wages[ max_common_nucleotides[j] ]\n",
    "        \n",
    "        \n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#określona już waga jest równomiernie rozdzielona na wyrazy o poszczególnej długości maksymalnego zazębienia\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_chance_for_first_word_2_with_numpy_tricks(problem_properties):\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    max_common_nucleotides = problem_properties.common_nucleotides_matrix.max(0)\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag, waga jest równomiernie rozdizelona\n",
    "    occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "    unique, counts = np.unique(max_common_nucleotides[1:], return_counts=True)\n",
    "    occurrence_counter[unique] = counts\n",
    "\n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.flip(np.copy(problem_properties.wages))\n",
    "    occurrence_counter[occurrence_counter == 0] = 1\n",
    "    current_wages /= occurrence_counter\n",
    "\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    problem_properties.next_word_power_matrix[0, 1:] = current_wages[ max_common_nucleotides[1:]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#funkcja wybiera kolejny wyraz dla tworzonego ciągu\n",
    "#funkcja została napisana w jak najprostszy iteracyjny sposób\n",
    "def choose_next_word_full_iterating(problem_properties):\n",
    "    #print(\"avaible words przed: \" + str(problem_properties.avaible_words_number))\n",
    "    #wybranie odpowiednich wektorów z macierzy, które przechowują dane dla ostatnio wybranego słowa\n",
    "    common_nucleotides_vector = problem_properties.common_nucleotides_matrix[problem_properties.current_word]\n",
    "    next_word_power_vector = problem_properties.next_word_power_matrix[problem_properties.current_word]\n",
    "    \n",
    "    #jeśli obecna długość wynikowego ciągu zwiększona o pełną długość kolejnego słowa przekracza ograniczającą długość ciągu znaków,\n",
    "    #to trzeba wykluczyć możliwość wyboru kolejnego słowa, które by to za bardzo zwiększyła długość wynikowej sekwencji\n",
    "    #print(str(problem_properties.current_length) + \" + \" + str(problem_properties.word_len) + \" > \" + str(problem_properties.org_seq_len))\n",
    "    if(problem_properties.current_length + problem_properties.word_len > problem_properties.org_seq_len):\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            if((problem_properties.avaible_words[j]) and (problem_properties.current_length + (problem_properties.word_len - common_nucleotides_vector[j]) > problem_properties.org_seq_len)):\n",
    "                problem_properties.avaible_words[j] = False\n",
    "                problem_properties.avaible_words_number -= 1\n",
    "        \n",
    "        #print(\"Juz prawie koniec - mozna dopasowac jeszcze \" + str(problem_properties.avaible_words_number) + \" slow\")\n",
    "    \n",
    "    #nie ma już dostępnych słów do doklejenia\n",
    "    if(not(problem_properties.avaible_words_number)):\n",
    "        return -1\n",
    "    \n",
    "    #obliczenie sumy mocy prawdopodobieństwa wyboru dla dostępnych słów\n",
    "    sum_of_probability = 0\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        if(problem_properties.avaible_words[j]):\n",
    "            sum_of_probability += next_word_power_vector[j]\n",
    "\n",
    "            \n",
    "    \"\"\"#print(str(max_sum) + \" < \" + str(sum_of_probability))\n",
    "    if(max_sum < sum_of_probability):\n",
    "        max_sum = sum_of_probability\n",
    "        print(\"sum_of_probability = \" + str(sum_of_probability))\"\"\"\n",
    "    \n",
    "    #realizacja wyboru zgodnie z gęstością prawdopodobieństwa - wybór punktu na odcinku złożonego z sumy mocy prawdopodobieństwa dostępnych połączeń\n",
    "    point_in_range_of_sum_of_probability = random.uniform(0, sum_of_probability)\n",
    "    \n",
    "    #odnalezienie wybranego kolejnego słowa, które zostało wskazane przez wylosowany punkt na odcinku\n",
    "    j = 1\n",
    "    while(not(problem_properties.avaible_words[j])):\n",
    "        j += 1\n",
    "    \n",
    "    current_sum_of_probability = next_word_power_vector[j]\n",
    "    while(point_in_range_of_sum_of_probability > current_sum_of_probability):\n",
    "        j += 1\n",
    "        while(not(problem_properties.avaible_words[j])):\n",
    "            j += 1\n",
    "        current_sum_of_probability += next_word_power_vector[j]\n",
    "    \n",
    "    #print(\"avaible words po: \" + str(problem_properties.avaible_words_number))\n",
    "    \n",
    "    return j\n",
    "\n",
    "#funkcja wybiera kolejny wyraz dla tworzonego ciągu\n",
    "#zwektoryzowana funkcja korzystająca z np.random.choice\n",
    "def choose_next_word_with_numpy_tricks_1(problem_properties):\n",
    "    #print(\"avaible words przed: \" + str(problem_properties.avaible_words_number))\n",
    "    #wybranie odpowiednich wektorów z macierzy, które przechowują dane dla ostatnio wybranego słowa\n",
    "    common_nucleotides_vector = problem_properties.common_nucleotides_matrix[problem_properties.current_word]\n",
    "    next_word_power_vector = problem_properties.next_word_power_matrix[problem_properties.current_word]\n",
    "    \n",
    "    #jeśli obecna długość wynikowego ciągu zwiększona o pełną długość kolejnego słowa przekracza ograniczającą długość ciągu znaków,\n",
    "    #to trzeba wykluczyć możliwość wyboru kolejnego słowa, które by to za bardzo zwiększyła długość wynikowej sekwencji\n",
    "    #print(str(problem_properties.current_length) + \" + \" + str(problem_properties.word_len) + \" > \" + str(problem_properties.org_seq_len))\n",
    "    if(problem_properties.current_length + problem_properties.word_len > problem_properties.org_seq_len):\n",
    "        mask = problem_properties.avaible_words * (problem_properties.current_length + problem_properties.word_len - common_nucleotides_vector > problem_properties.org_seq_len)\n",
    "        problem_properties.avaible_words[mask] = False\n",
    "        problem_properties.avaible_words_number -= np.sum(mask)\n",
    "        \n",
    "        #print(\"Juz prawie koniec - mozna dopasowac jeszcze \" + str(problem_properties.avaible_words_number) + \" slow\")\n",
    "    \n",
    "    #nie ma już dostępnych słów do doklejenia\n",
    "    if(not(problem_properties.avaible_words_number)):\n",
    "        return -1\n",
    "    \n",
    "    #realizacja wyboru zgodnie z gęstością prawdopodobieństwa\n",
    "    indices = np.arange(problem_properties.words_num + 1)\n",
    "    p_active = next_word_power_vector[ problem_properties.avaible_words ]\n",
    "    p_sum = np.sum(p_active)\n",
    "    p_active = p_active / p_sum\n",
    "    index = np.random.choice(indices[ problem_properties.avaible_words ], 1, p=p_active)\n",
    "    \n",
    "    #print(\"avaible words po: \" + str(problem_properties.avaible_words_number))\n",
    "    \n",
    "    return index[0]\n",
    "\n",
    "#funkcja wybiera kolejny wyraz dla tworzonego ciągu\n",
    "#zwektoryzowana funkcja odpowiadająca idei wersji iteracyjnej\n",
    "def choose_next_word_with_numpy_tricks_2(problem_properties):\n",
    "    #print(\"avaible words przed: \" + str(problem_properties.avaible_words_number))\n",
    "    #wybranie odpowiednich wektorów z macierzy, które przechowują dane dla ostatnio wybranego słowa\n",
    "    common_nucleotides_vector = problem_properties.common_nucleotides_matrix[problem_properties.current_word]\n",
    "    next_word_power_vector = problem_properties.next_word_power_matrix[problem_properties.current_word]\n",
    "    \n",
    "    #jeśli obecna długość wynikowego ciągu zwiększona o pełną długość kolejnego słowa przekracza ograniczającą długość ciągu znaków,\n",
    "    #to trzeba wykluczyć możliwość wyboru kolejnego słowa, które by to za bardzo zwiększyła długość wynikowej sekwencji\n",
    "    #print(str(problem_properties.current_length) + \" + \" + str(problem_properties.word_len) + \" > \" + str(problem_properties.org_seq_len))\n",
    "    if(problem_properties.current_length + problem_properties.word_len > problem_properties.org_seq_len):\n",
    "        mask = problem_properties.avaible_words * (problem_properties.current_length + problem_properties.word_len - common_nucleotides_vector > problem_properties.org_seq_len)\n",
    "        problem_properties.avaible_words[mask] = False\n",
    "        problem_properties.avaible_words_number -= np.sum(mask)\n",
    "        \n",
    "        #print(\"Juz prawie koniec - mozna dopasowac jeszcze \" + str(problem_properties.avaible_words_number) + \" slow\")\n",
    "    \n",
    "    #nie ma już dostępnych słów do doklejenia\n",
    "    if(not(problem_properties.avaible_words_number)):\n",
    "        return -1\n",
    "    \n",
    "    #wydzielenie potrzebnych danych o dostępnych do wyboru słowach\n",
    "    next_word_power_not_used = next_word_power_vector[ problem_properties.avaible_words ]\n",
    "    indices = np.arange(problem_properties.words_num + 1)[ problem_properties.avaible_words ]\n",
    "    \n",
    "    #obliczenie sumy mocy prawdopodobieństwa wyboru dla dostępnych słów\n",
    "    sum_of_probability = np.sum(next_word_power_not_used)\n",
    "    \n",
    "    #realizacja wyboru zgodnie z gęstością prawdopodobieństwa - wybór punktu na odcinku złożonego z sumy mocy prawdopodobieństwa dostępnych połączeń\n",
    "    point_in_range_of_sum_of_probability = random.uniform(0, sum_of_probability)\n",
    "    \n",
    "    #odnalezienie wybranego kolejnego słowa, które zostało wskazane przez wylosowany punkt na odcinku\n",
    "    j = 0\n",
    "    current_sum_of_probability = next_word_power_not_used[j]\n",
    "    while(point_in_range_of_sum_of_probability > current_sum_of_probability):\n",
    "        j += 1\n",
    "        current_sum_of_probability += next_word_power_not_used[j]\n",
    "    \n",
    "    return indices[j]\n",
    "\n",
    "#funkcja wybiera kolejny wyraz dla tworzonego ciągu\n",
    "#zwektoryzowana funkcja korzystająca z bisekcji\n",
    "def choose_next_word_with_numpy_tricks_3(problem_properties):\n",
    "    #wybranie odpowiednich wektorów z macierzy, które przechowują dane dla ostatnio wybranego słowa\n",
    "    common_nucleotides_vector = problem_properties.common_nucleotides_matrix[problem_properties.current_word]\n",
    "    next_word_power_vector = problem_properties.next_word_power_matrix[problem_properties.current_word]\n",
    "    \n",
    "    #jeśli obecna długość wynikowego ciągu zwiększona o pełną długość kolejnego słowa przekracza ograniczającą długość ciągu znaków,\n",
    "    #to trzeba wykluczyć możliwość wyboru kolejnego słowa, które by to za bardzo zwiększyła długość wynikowej sekwencji\n",
    "    #print(str(problem_properties.current_length) + \" + \" + str(problem_properties.word_len) + \" > \" + str(problem_properties.org_seq_len))\n",
    "    if(problem_properties.current_length + problem_properties.word_len > problem_properties.org_seq_len):\n",
    "        mask = problem_properties.avaible_words * (problem_properties.current_length + problem_properties.word_len - common_nucleotides_vector > problem_properties.org_seq_len)\n",
    "        problem_properties.avaible_words[mask] = False\n",
    "        problem_properties.avaible_words_number -= np.sum(mask)\n",
    "        \n",
    "        #print(\"Juz prawie koniec - mozna dopasowac jeszcze \" + str(problem_properties.avaible_words_number) + \" slow\")\n",
    "    \n",
    "    #nie ma już dostępnych słów do doklejenia\n",
    "    if(not(problem_properties.avaible_words_number)):\n",
    "        return -1\n",
    "    \n",
    "    #wydzielenie potrzebnych danych o dostępnych do wyboru słowach\n",
    "    next_word_power_not_used = next_word_power_vector[ problem_properties.avaible_words ]\n",
    "    indices = np.arange(problem_properties.words_num + 1)[ problem_properties.avaible_words ]\n",
    "    \n",
    "    #obliczenie sumy mocy prawdopodobieństwa wyboru dla dostępnych słów\n",
    "    sum_of_probability = np.sum(next_word_power_not_used)\n",
    "    \n",
    "    #realizacja wyboru zgodnie z gęstością prawdopodobieństwa - wybór punktu na odcinku złożonego z sumy mocy prawdopodobieństwa dostępnych połączeń\n",
    "    point_in_range_of_sum_of_probability = random.uniform(0, sum_of_probability)    \n",
    "    \n",
    "    #odnalezienie wybranego kolejnego słowa, które zostało wskazane przez wylosowany punkt na odcinku\n",
    "    P = 0\n",
    "    K = next_word_power_not_used.size - 1\n",
    "    while(P != K):\n",
    "        S = (P + K) // 2\n",
    "        if(np.sum(next_word_power_not_used[:S+1]) < point_in_range_of_sum_of_probability):\n",
    "            P = S + 1\n",
    "        else:\n",
    "            K = S\n",
    "    \n",
    "    return indices[P]\n",
    "\n",
    "#funkcja wybiera kolejny wyraz dla tworzonego ciągu\n",
    "#zwektoryzowana funkcja korzystająca z np.cumsum\n",
    "def choose_next_word_with_numpy_tricks_4(problem_properties):\n",
    "    #wybranie odpowiednich wektorów z macierzy, które przechowują dane dla ostatnio wybranego słowa\n",
    "    common_nucleotides_vector = problem_properties.common_nucleotides_matrix[problem_properties.current_word]\n",
    "    next_word_power_vector = problem_properties.next_word_power_matrix[problem_properties.current_word]\n",
    "    \n",
    "    #jeśli obecna długość wynikowego ciągu zwiększona o pełną długość kolejnego słowa przekracza ograniczającą długość ciągu znaków,\n",
    "    #to trzeba wykluczyć możliwość wyboru kolejnego słowa, które by to za bardzo zwiększyła długość wynikowej sekwencji\n",
    "    #print(str(problem_properties.current_length) + \" + \" + str(problem_properties.word_len) + \" > \" + str(problem_properties.org_seq_len))\n",
    "    if(problem_properties.current_length + problem_properties.word_len > problem_properties.org_seq_len):\n",
    "        mask = problem_properties.avaible_words * (problem_properties.current_length + problem_properties.word_len - common_nucleotides_vector > problem_properties.org_seq_len)\n",
    "        problem_properties.avaible_words[mask] = False\n",
    "        problem_properties.avaible_words_number -= np.sum(mask)\n",
    "        \n",
    "        #print(\"Juz prawie koniec - mozna dopasowac jeszcze \" + str(problem_properties.avaible_words_number) + \" slow\")\n",
    "    \n",
    "    #nie ma już dostępnych słów do doklejenia\n",
    "    if(not(problem_properties.avaible_words_number)):\n",
    "        return -1\n",
    "    \n",
    "    #wydzielenie potrzebnych danych o dostępnych do wyboru słowach\n",
    "    next_word_power_not_used = next_word_power_vector[ problem_properties.avaible_words ]\n",
    "    indices = np.arange(problem_properties.words_num + 1)[ problem_properties.avaible_words ]\n",
    "    \n",
    "    #wyznaczenie kumulacyjnej sumy z wektora wag prawdopodobieństw dostępnych wyrazów\n",
    "    next_word_power_not_used_cumsum = np.zeros(next_word_power_not_used.shape)\n",
    "    np.cumsum(next_word_power_not_used, out=next_word_power_not_used_cumsum)\n",
    "    \n",
    "    #realizacja wyboru zgodnie z gęstością prawdopodobieństwa - wybór punktu na odcinku złożonego z sumy mocy prawdopodobieństwa dostępnych połączeń\n",
    "    point_in_range_of_sum_of_probability = random.uniform(0, next_word_power_not_used_cumsum[-1])\n",
    "    \n",
    "    #odnalezienie wybranego kolejnego słowa, które zostało wskazane przez wylosowany punkt na odcinku\n",
    "    j = np.searchsorted(next_word_power_not_used_cumsum, point_in_range_of_sum_of_probability)\n",
    "    \n",
    "    return indices[j]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_sequence(problem_properties, choose_next_word_function):\n",
    "    problem_properties.prepare_attempts_vars()\n",
    "\n",
    "    problem_properties.avaible_words[0] = False        #odznaczenie użycia już zerowego słowa ('X')\n",
    "    problem_properties.current_word = 0            #ustawienie startowego słowa -> słowo zerowe, czyli zaczynane jest tworzenie sekwencji\n",
    "    problem_properties.sequence.append(problem_properties.current_word)\n",
    "\n",
    "    #nieustannie wykonująca się pętla - zostanie przerwana, gdy nie będzie już możliwości doczepienia słowa przy ograniczeniu ilości znaków w wynikowym ciągu\n",
    "    while(True):\n",
    "        next_word = choose_next_word_function(problem_properties)\n",
    "        #print(\"Wybrane slowo: \" + str(next_word))\n",
    "\n",
    "        if(next_word == -1):\n",
    "            break\n",
    "\n",
    "        problem_properties.current_length += problem_properties.word_len - problem_properties.common_nucleotides_matrix[problem_properties.current_word, next_word]\n",
    "        problem_properties.avaible_words_number -= 1\n",
    "        problem_properties.avaible_words[next_word] = False\n",
    "\n",
    "        \"\"\"print(problem_properties.words[problem_properties.current_word])\n",
    "        print((problem_properties.word_len - problem_properties.common_nucleotides_matrix[problem_properties.current_word, next_word]) * ' ' + problem_properties.words[problem_properties.next_word] + \"\\tPokrywanie na tylu znakach: \" + str(problem_properties.common_nucleotides_matrix[problem_properties.current_word, next_word]))\n",
    "        print(\"Liczba niewykorzystanych jeszcze slow: \" + str(problem_properties.avaible_words_number))\n",
    "        print(\"Obecna dlugosc ciagu: \" + str(problem_properties.current_length))\n",
    "        print(\"\\n\")\"\"\"\n",
    "\n",
    "        problem_properties.current_word = next_word\n",
    "        problem_properties.sequence.append(problem_properties.current_word)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#funkcja dokonuje wygładzania wartości wag prawdopodobieństw -> zmienia szanse wyboru na bardziej równe, zachowująć jednocześnie porządek preferencji\n",
    "def compensation_of_next_word_power_matrix_full_iterating(problem_properties):\n",
    "    \n",
    "    for i in range(problem_properties.words_num + 1):\n",
    "        max_value = np.max(problem_properties.next_word_power_matrix[i])\n",
    "        sum_value = np.sum(problem_properties.next_word_power_matrix[i])\n",
    "        \n",
    "        #jeśli maksymalna wartość zdecydowanie się wyróżnia, to należy złagodzić dysproporcje między wagami prawdopodobieństw\n",
    "        #print(\"max_value = \" + str(max_value))\n",
    "        #print(\"sum_value * problem_properties.compensation_coef = \" + str(sum_value * problem_properties.compensation_coef))\n",
    "        if(max_value > sum_value * problem_properties.compensation_coef):\n",
    "            #poszukiwanie minimalnej wartości wagi prawdopodobieństwa nie mniejszej niż wartość 1. Wartość ta jest potrzebna do wzoru wygładzającego\n",
    "            min_value = max_value\n",
    "            for j in range(problem_properties.words_num + 1):\n",
    "                if((problem_properties.next_word_power_matrix[i, j] >= 1) and (min_value > problem_properties.next_word_power_matrix[i, j])):\n",
    "                    min_value = problem_properties.next_word_power_matrix[i, j]\n",
    "            \n",
    "            #wygładzanie wag większych niż wartość 1\n",
    "            for j in range(problem_properties.words_num + 1):\n",
    "                if(min_value < problem_properties.next_word_power_matrix[i, j]):\n",
    "                    problem_properties.next_word_power_matrix[i, j] = min_value * (1 + math.log(problem_properties.next_word_power_matrix[i, j] / min_value, problem_properties.base_of_logarithm))\n",
    "\n",
    "#funkcja dokonuje wygładzania wartości wag prawdopodobieństw -> zmienia szanse wyboru na bardziej równe, zachowująć jednocześnie porządek preferencji\n",
    "#operacja zmiany wag w danym wierszu została tutaj zwektoryzowana\n",
    "def compensation_of_next_word_power_matrix_with_numpy_tricks_1(problem_properties):\n",
    "    \n",
    "    for i in range(problem_properties.words_num + 1):\n",
    "        max_value = np.max(problem_properties.next_word_power_matrix[i])\n",
    "        sum_value = np.sum(problem_properties.next_word_power_matrix[i])\n",
    "        \n",
    "        #jeśli maksymalna wartość zdecydowanie się wyróżnia, to należy złagodzić dysproporcje między wagami prawdopodobieństw\n",
    "        #print(\"max_value = \" + str(max_value))\n",
    "        #print(\"sum_value * problem_properties.compensation_coef = \" + str(sum_value * problem_properties.compensation_coef))\n",
    "        if(max_value > sum_value * problem_properties.compensation_coef):\n",
    "            #poszukiwanie minimalnej wartości wagi prawdopodobieństwa nie mniejszej niż wartość 1. Wartość ta jest potrzebna do wzoru wygładzającego\n",
    "            min_value = min(problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] >= 1])\n",
    "            \n",
    "            #wygładzanie wag większych niż wartość 1\n",
    "            problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] > min_value] = min_value * (1 + np.log(problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] > min_value] / min_value) / np.log(problem_properties.base_of_logarithm))\n",
    "\n",
    "#funkcja dokonuje wygładzania wartości wag prawdopodobieństw -> zmienia szanse wyboru na bardziej równe, zachowująć jednocześnie porządek preferencji\n",
    "#cała procedura została zwektoryzowana\n",
    "def compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties):\n",
    "    \n",
    "    max_value = np.max(problem_properties.next_word_power_matrix, axis=1)\n",
    "    sum_value = np.sum(problem_properties.next_word_power_matrix, axis=1)\n",
    "    \n",
    "    #odwzorowanie maksymalnych wartości wierszy na całą macierz\n",
    "    max_value_matrix = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1))\n",
    "    max_value_matrix[:] = max_value\n",
    "    max_value_matrix = max_value_matrix.transpose()\n",
    "\n",
    "    #odwzorowanie sumy wartości wierszy na całą macierz\n",
    "    sum_value_matrix = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1))\n",
    "    sum_value_matrix[:] = sum_value\n",
    "    sum_value_matrix = sum_value_matrix.transpose()\n",
    "\n",
    "    #wskazanie wierszy w macierzy, w których trzeba wykonać wygładzanie\n",
    "    mask_row = max_value_matrix > sum_value_matrix * problem_properties.compensation_coef\n",
    "\n",
    "    #przygotowanie kopii next_word_power_matrix, którą będzie trzeba zmodyfikować w celu odnalezienia minimalnej wartości większej niż 1 dla każdego wiersza\n",
    "    tmp_next_word_power_matrix = np.copy(problem_properties.next_word_power_matrix)\n",
    "    mask_tmp = tmp_next_word_power_matrix < 1\n",
    "    tmp_next_word_power_matrix[mask_tmp] = max_value_matrix[mask_tmp]\n",
    "\n",
    "    #wyznaczenie i odwzorowanie na całą macierz minimalnej wartości większej niż 1 dla każdego wiersza\n",
    "    min_value = np.min(tmp_next_word_power_matrix, axis=1)\n",
    "    min_value_matrix = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1))\n",
    "    min_value_matrix[:] = min_value\n",
    "    min_value_matrix = min_value_matrix.transpose()\n",
    "\n",
    "    #wskazanie elementów, które należy zmodyfikować\n",
    "    mask_final = ((problem_properties.next_word_power_matrix >= min_value_matrix) * (mask_row))\n",
    "\n",
    "    #wykonanie faktycznego wygładzania dominujących wartości w problem_properties.next_word_power_matrix\n",
    "    min_value_vector = min_value_matrix[mask_final]\n",
    "    problem_properties.next_word_power_matrix[mask_final] = min_value_vector * (1 + np.log(problem_properties.next_word_power_matrix[mask_final] / min_value_vector) / np.log(problem_properties.base_of_logarithm))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#funkcja zwraca długość utworzonej sekwencji na podstawie indeksów wyrazów i macierzy zawierającej długości wspólnych sufiksów-prefiksów wszystkich par słów.\n",
    "def length_of_created_sequence_full_iterating(sequence, common_nucleotides_matrix, word_len):\n",
    "    result = 0\n",
    "    for i in range(len(sequence) - 1):\n",
    "        result += word_len - common_nucleotides_matrix[sequence[i], sequence[i + 1]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "#funkcja zwraca długość utworzonej sekwencji na podstawie indeksów wyrazów i macierzy zawierającej długości wspólnych sufiksów-prefiksów wszystkich par słów.\n",
    "#przyspieszenie przetwarzania poprzez wektoryzację obliczeń\n",
    "def length_of_created_sequence_with_numpy_tricks(sequence, common_nucleotides_matrix, word_len):\n",
    "    first_word = sequence[:-1]\n",
    "    second_word = sequence[1:]\n",
    "    \n",
    "    result = np.sum(word_len - common_nucleotides_matrix[first_word, second_word])\n",
    "    return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#funkcja nagradza najlepsze rozwiązania przeprowadzając odpowiednie modyfikacje w macierzy wag prawdopodobieństw\n",
    "def reward_the_best_solutions_full_iterating(problem_properties):\n",
    "    \n",
    "    \"\"\"for i in range(len(problem_properties.sequences)):\n",
    "        print(str(i) + \":\\t\" + str(len(problem_properties.sequences[i])))\"\"\"\n",
    "    \n",
    "    problem_properties.sequences.sort(key = lambda x: length_of_created_sequence_with_numpy_tricks(x, problem_properties.common_nucleotides_matrix, problem_properties.word_len), reverse=False)\n",
    "    problem_properties.sequences.sort(key = lambda x: len(x), reverse=True)\n",
    "\n",
    "    \"\"\"for i in range(len(problem_properties.sequences)):\n",
    "        print(str(i) + \":\\t\" + str(len(problem_properties.sequences[i])))\"\"\"\n",
    "\n",
    "    #nagrodzenie najlepszych rozwiązań\n",
    "    amount_of_the_best_sequences = int(problem_properties.attempts_number * problem_properties.part_of_the_best_sequences)\n",
    "    \"\"\"for i in range(amount_of_the_best_sequences):\n",
    "        print(str(i) + \":\\t\" + str(len(problem_properties.sequences[i])))\"\"\"\n",
    "    for iSequence in range(amount_of_the_best_sequences):\n",
    "        sequence = problem_properties.sequences[iSequence]\n",
    "        price_for_sequence = 1 + (problem_properties.best_price_for_sequence - 1) * ((amount_of_the_best_sequences - iSequence) / amount_of_the_best_sequences)\n",
    "        #print(\"price_for_sequence = \" + str(price_for_sequence))\n",
    "        for iConnection in range(len(sequence) - 1):\n",
    "            first_word = sequence[iConnection]\n",
    "            second_word = sequence[iConnection + 1]\n",
    "\n",
    "            price_for_connection = 1 + (price_for_sequence - 1) * (problem_properties.common_nucleotides_matrix[first_word, second_word] / (problem_properties.word_len - 1))\n",
    "            problem_properties.next_word_power_matrix[first_word, second_word] *= price_for_connection\n",
    "\n",
    "\n",
    "        \"\"\"wyswietlanie mnożnika dla połączeń - im bardziej wyrazy się zazębiają, tym większa liniowo jest wartość mnożnika\n",
    "        for i in range(problem_properties.word_len):\n",
    "            price_for_connection = 1 + (price_for_sequence - 1) * (i / (problem_properties.word_len - 1))\n",
    "            print(\"price_for_connection = \" + str(price_for_connection))\"\"\"\n",
    "        \n",
    "#funkcja nagradza najlepsze rozwiązania przeprowadzając odpowiednie modyfikacje w macierzy wag prawdopodobieństw\n",
    "#przyspieszenie przetwarzania poprzez wektoryzację obliczeń\n",
    "def reward_the_best_solutions_with_numpy_tricks(problem_properties):\n",
    "\n",
    "    problem_properties.sequences.sort(key = lambda x: length_of_created_sequence_with_numpy_tricks(x, problem_properties.common_nucleotides_matrix, problem_properties.word_len), reverse=False)\n",
    "    problem_properties.sequences.sort(key = lambda x: len(x), reverse=True)\n",
    "\n",
    "    #nagrodzenie najlepszych rozwiązań\n",
    "    amount_of_the_best_sequences = int(problem_properties.attempts_number * problem_properties.part_of_the_best_sequences)\n",
    "    for iSequence in range(amount_of_the_best_sequences):\n",
    "        sequence = np.array(problem_properties.sequences[iSequence])\n",
    "        price_for_sequence = 1 + (problem_properties.best_price_for_sequence - 1) * ((amount_of_the_best_sequences - iSequence) / amount_of_the_best_sequences)\n",
    "        #print(\"price_for_sequence = \" + str(price_for_sequence))\n",
    "        \n",
    "        first_word = sequence[:-1]\n",
    "        second_word = sequence[1:]\n",
    "        price_for_connection = 1 + (price_for_sequence - 1) * (problem_properties.common_nucleotides_matrix[first_word, second_word] / (problem_properties.word_len - 1))\n",
    "        problem_properties.next_word_power_matrix[first_word, second_word] *= price_for_connection\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#funkcja wykonuje zapisanie długości otrzymanych sekwencji do listy sequences_lengths_of_all_iterations\n",
    "def remember_sequences_lengths_full_iterating(problem_properties):\n",
    "    \n",
    "    result = np.zeros(problem_properties.attempts_number, dtype=int)\n",
    "    \n",
    "    for i in range(problem_properties.attempts_number):\n",
    "        result[i] = len(problem_properties.sequences[i])\n",
    "    \n",
    "    problem_properties.sequences_lengths_of_all_iterations.append(result)\n",
    "    \n",
    "\n",
    "        \n",
    "#funkcja wykonuje zapisanie długości otrzymanych sekwencji do listy sequences_lengths_of_all_iterations\n",
    "#przyspieszenie przetwarzania poprzez wektoryzację obliczeń\n",
    "def remember_sequences_lengths_with_numpy_tricks(problem_properties):\n",
    "    \n",
    "    result = np.array(list(map(len, problem_properties.sequences)))\n",
    "    \n",
    "    problem_properties.sequences_lengths_of_all_iterations.append(result)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def run_ant_algorithm_constant_iteration_number_with_message(problem_properties, filename, method_of_probability_assignment=2):\n",
    "    random.seed(0)\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        print(\"nazwa pliku: \" + inst_name)\n",
    "        print(\"długość słowa: \" + str(word_len))\n",
    "        print(\"oryginalna liczba słów: \" + str(org_words_num))\n",
    "        print(\"oryginalna długość sekwencji: \"+ str(org_seq_len))\n",
    "        print(\"liczba błędów negatywnych: \" + str(neg_errors_number))\n",
    "        print(\"liczba błędów pozytywnych: \" + str(pos_errors_number))\n",
    "        print(\"liczba oligonukleotydów: \" + str(words_num))\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "        print(words[:5])\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "        #zapisanie ważnych informacji w obiekcie klasy ProblemPropertiesClass\n",
    "        problem_properties.set_instance_info(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        print(\"common_nucleotides_matrix()\")\n",
    "        generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "        #print(common_nucleotides_matrix[0, :])\n",
    "\n",
    "        print(\"set_starting_wages()\")\n",
    "        problem_properties.wages = set_starting_wages(problem_properties.word_len, problem_properties.k_set_starting_wages)\n",
    "        #print(wages)\n",
    "\n",
    "\n",
    "        #wyznaczanie macierzy mocy prawdopodobieństwa następienia j-tego wyrazu po i-tym\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            print(\"generate_next_word_power_matrix_1_with_numpy_tricks()\")\n",
    "            generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            print(\"generate_next_word_power_matrix_2_with_numpy_tricks_2()\")\n",
    "            generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties)\n",
    "\n",
    "        #ustawienie wag prawdopodobieństwa dla rozpoczęcia tworzenia sekwencji przez dany wyraz\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            print(\"generate_chance_for_first_word_1_with_numpy_tricks()\")\n",
    "            generate_chance_for_first_word_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            print(\"generate_chance_for_first_word_2_with_numpy_tricks()\")\n",
    "            generate_chance_for_first_word_2_with_numpy_tricks(problem_properties)\n",
    "\n",
    "        #wykonywanie poszczególnej iteracji; wykonywanie pętli tyle razy, ile jest zadeklarowanych iteracji do wykonania\n",
    "        for indeks_of_iteration in range(problem_properties.iterations_number):\n",
    "            problem_properties.prepare_iterations_vars()\n",
    "\n",
    "\n",
    "            #tworzenie wynikowej sekwencji; powtarzanie prób uzyskania rozwiązania tyle razy, ile jest to określone parametrem 'problem_properties.attempts_number'\n",
    "            print(\"\\nIteracja \" + str(indeks_of_iteration + 1) + \":\\t\\nTrwa wykonywanie wszystkich \" + str(problem_properties.attempts_number) + \" prób utworzenia wynikowej sekwencji.\")\n",
    "            for indeks_of_attempt in range(problem_properties.attempts_number):\n",
    "                #utworzenie sekwencji\n",
    "                create_sequence(problem_properties, choose_next_word_with_numpy_tricks_4)\n",
    "\n",
    "                #zapamiętanie uzyskanej sekwencji\n",
    "                problem_properties.sequences.append(problem_properties.sequence)\n",
    "\n",
    "\n",
    "            print(\"Wykonano wszystkie sekwencje w obecnej iteracji\")\n",
    "\n",
    "\n",
    "            #nagrodzenie najlepszych rozwiązań przeprowadzając odpowiednie modyfikacje w macierzy wag prawdopodobieństw\n",
    "            print(\"reward_the_best_solutions_full_iterating()\")\n",
    "            reward_the_best_solutions_with_numpy_tricks(problem_properties)\n",
    "            \n",
    "            #zapamiętanie ewentualnego lepszego rozwiązania składającego się z większej ilości wyrazów\n",
    "            tmp_len = len(problem_properties.sequences[0])\n",
    "            if(problem_properties.best_sequence_len < tmp_len):\n",
    "                problem_properties.best_sequence_len = tmp_len\n",
    "                problem_properties.best_sequence = problem_properties.sequences[0]\n",
    "                problem_properties.iteration_with_the_best_sequence = indeks_of_iteration + 1\n",
    "\n",
    "\n",
    "            print(problem_properties.sequences[0])\n",
    "            for i in range(10):\n",
    "                znaki = length_of_created_sequence_with_numpy_tricks(problem_properties.sequences[i], problem_properties.common_nucleotides_matrix, problem_properties.word_len)\n",
    "                print(str(i) + \":\\twyrazy: \" + str(len(problem_properties.sequences[i]) - 1) + \"\\tznaki: \" + str(znaki))\n",
    "            \n",
    "            \n",
    "            #wywołanie funkcji zapamiętującej długości wszystkich uzyskanych sekwencji w danej iteracji\n",
    "            print(\"remember_sequences_lengths_with_numpy_tricks()\")\n",
    "            remember_sequences_lengths_with_numpy_tricks(problem_properties)\n",
    "            \n",
    "\n",
    "            #wygładzanie macierzy wag prawdopodobieństwa w celu zapobiegnięcia nadmiernemu zdominowaniu przez najlepsze rozwiązanie\n",
    "            print(\"compensation_of_next_word_power_matrix()\")\n",
    "            compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties)\n",
    "\n",
    "        print(\"koniec\")\n",
    "    \n",
    "\n",
    "\n",
    "def run_ant_algorithm_constant_iteration_number(problem_properties, filename, method_of_probability_assignment=2):\n",
    "    random.seed(0)\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "\n",
    "\n",
    "        #zapisanie ważnych informacji w obiekcie klasy ProblemPropertiesClass\n",
    "        problem_properties.set_instance_info(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "        #print(common_nucleotides_matrix[0, :])\n",
    "\n",
    "        problem_properties.wages = set_starting_wages(problem_properties.word_len, problem_properties.k_set_starting_wages)\n",
    "        #print(wages)\n",
    "\n",
    "\n",
    "        #wyznaczanie macierzy mocy prawdopodobieństwa następienia j-tego wyrazu po i-tym\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties)\n",
    "\n",
    "        #ustawienie wag prawdopodobieństwa dla rozpoczęcia tworzenia sekwencji przez dany wyraz\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            generate_chance_for_first_word_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            generate_chance_for_first_word_2_with_numpy_tricks(problem_properties)\n",
    "\n",
    "        #wykonywanie poszczególnej iteracji; wykonywanie pętli tyle razy, ile jest zadeklarowanych iteracji do wykonania\n",
    "        for indeks_of_iteration in range(problem_properties.iterations_number):\n",
    "            problem_properties.prepare_iterations_vars()\n",
    "\n",
    "\n",
    "            #tworzenie wynikowej sekwencji; powtarzanie prób uzyskania rozwiązania tyle razy, ile jest to określone parametrem 'problem_properties.attempts_number'\n",
    "            for indeks_of_attempt in range(problem_properties.attempts_number):\n",
    "                #utworzenie sekwencji\n",
    "                create_sequence(problem_properties, choose_next_word_with_numpy_tricks_4)\n",
    "\n",
    "                #zapamiętanie uzyskanej sekwencji\n",
    "                problem_properties.sequences.append(problem_properties.sequence)\n",
    "                \n",
    "\n",
    "\n",
    "            #nagrodzenie najlepszych rozwiązań przeprowadzając odpowiednie modyfikacje w macierzy wag prawdopodobieństw\n",
    "            reward_the_best_solutions_with_numpy_tricks(problem_properties)\n",
    "            \n",
    "            #zapamiętanie ewentualnego lepszego rozwiązania składającego się z większej ilości wyrazów\n",
    "            tmp_len = len(problem_properties.sequences[0])\n",
    "            if(problem_properties.best_sequence_len < tmp_len):\n",
    "                problem_properties.best_sequence_len = tmp_len\n",
    "                problem_properties.best_sequence = problem_properties.sequences[0]\n",
    "                problem_properties.iteration_with_the_best_sequence = indeks_of_iteration + 1\n",
    "\n",
    "                \n",
    "            \n",
    "            #wywołanie funkcji zapamiętującej długości wszystkich uzyskanych sekwencji w danej iteracji\n",
    "            remember_sequences_lengths_with_numpy_tricks(problem_properties)\n",
    "            \n",
    "\n",
    "            #wygładzanie macierzy wag prawdopodobieństwa w celu zapobiegnięcia nadmiernemu zdominowaniu przez najlepsze rozwiązanie\n",
    "            compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties)\n",
    "\n",
    "\n",
    "\n",
    "def run_ant_algorithm_with_message(problem_properties, filename, method_of_probability_assignment=2):\n",
    "    random.seed(0)\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        print(\"nazwa pliku: \" + inst_name)\n",
    "        print(\"długość słowa: \" + str(word_len))\n",
    "        print(\"oryginalna liczba słów: \" + str(org_words_num))\n",
    "        print(\"oryginalna długość sekwencji: \"+ str(org_seq_len))\n",
    "        print(\"liczba błędów negatywnych: \" + str(neg_errors_number))\n",
    "        print(\"liczba błędów pozytywnych: \" + str(pos_errors_number))\n",
    "        print(\"liczba oligonukleotydów: \" + str(words_num))\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "        print(words[:5])\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "        #zapisanie ważnych informacji w obiekcie klasy ProblemPropertiesClass\n",
    "        problem_properties.set_instance_info(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        print(\"common_nucleotides_matrix()\")\n",
    "        generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "        #print(common_nucleotides_matrix[0, :])\n",
    "\n",
    "        print(\"set_starting_wages()\")\n",
    "        problem_properties.wages = set_starting_wages(problem_properties.word_len, problem_properties.k_set_starting_wages)\n",
    "        #print(wages)\n",
    "\n",
    "\n",
    "        #wyznaczanie macierzy mocy prawdopodobieństwa następienia j-tego wyrazu po i-tym\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            print(\"generate_next_word_power_matrix_1_with_numpy_tricks()\")\n",
    "            generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            print(\"generate_next_word_power_matrix_2_with_numpy_tricks_2()\")\n",
    "            generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties)\n",
    "\n",
    "        #ustawienie wag prawdopodobieństwa dla rozpoczęcia tworzenia sekwencji przez dany wyraz\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            print(\"generate_chance_for_first_word_1_with_numpy_tricks()\")\n",
    "            generate_chance_for_first_word_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            print(\"generate_chance_for_first_word_2_with_numpy_tricks()\")\n",
    "            generate_chance_for_first_word_2_with_numpy_tricks(problem_properties)\n",
    "\n",
    "        #wykonywanie poszczególnej iteracji; wykonywanie pętli, dopóki po określonej liczbie iteracji nie znajdzie się lepsze rozwiązanie\n",
    "        problem_properties.iterations_number = 0\n",
    "        while(problem_properties.iterations_number - problem_properties.iteration_with_the_best_sequence < problem_properties.iterations_number_limit):\n",
    "            problem_properties.prepare_iterations_vars()\n",
    "            problem_properties.iterations_number += 1\n",
    "\n",
    "\n",
    "            #tworzenie wynikowej sekwencji; powtarzanie prób uzyskania rozwiązania tyle razy, ile jest to określone parametrem 'problem_properties.attempts_number'\n",
    "            print(\"\\nIteracja \" + str(problem_properties.iterations_number) + \":\\t\\nTrwa wykonywanie wszystkich \" + str(problem_properties.attempts_number) + \" prób utworzenia wynikowej sekwencji.\")\n",
    "            for indeks_of_attempt in range(problem_properties.attempts_number):\n",
    "                #utworzenie sekwencji\n",
    "                create_sequence(problem_properties, choose_next_word_with_numpy_tricks_4)\n",
    "\n",
    "                #zapamiętanie uzyskanej sekwencji\n",
    "                problem_properties.sequences.append(problem_properties.sequence)\n",
    "\n",
    "\n",
    "            print(\"Wykonano wszystkie sekwencje w obecnej iteracji\")\n",
    "\n",
    "\n",
    "            #nagrodzenie najlepszych rozwiązań przeprowadzając odpowiednie modyfikacje w macierzy wag prawdopodobieństw\n",
    "            print(\"reward_the_best_solutions_full_iterating()\")\n",
    "            reward_the_best_solutions_with_numpy_tricks(problem_properties)\n",
    "            \n",
    "            #zapamiętanie ewentualnego lepszego rozwiązania składającego się z większej ilości wyrazów\n",
    "            tmp_len = len(problem_properties.sequences[0])\n",
    "            if(problem_properties.best_sequence_len < tmp_len):\n",
    "                problem_properties.best_sequence_len = tmp_len\n",
    "                problem_properties.best_sequence = problem_properties.sequences[0]\n",
    "                problem_properties.iteration_with_the_best_sequence = problem_properties.iterations_number\n",
    "\n",
    "\n",
    "            print(problem_properties.sequences[0])\n",
    "            for i in range(10):\n",
    "                znaki = length_of_created_sequence_with_numpy_tricks(problem_properties.sequences[i], problem_properties.common_nucleotides_matrix, problem_properties.word_len)\n",
    "                print(str(i) + \":\\twyrazy: \" + str(len(problem_properties.sequences[i]) - 1) + \"\\tznaki: \" + str(znaki))\n",
    "\n",
    "                \n",
    "            \n",
    "            #wywołanie funkcji zapamiętującej długości wszystkich uzyskanych sekwencji w danej iteracji\n",
    "            print(\"remember_sequences_lengths_with_numpy_tricks()\")\n",
    "            remember_sequences_lengths_with_numpy_tricks(problem_properties)\n",
    "\n",
    "            \n",
    "            #wygładzanie macierzy wag prawdopodobieństwa w celu zapobiegnięcia nadmiernemu zdominowaniu przez najlepsze rozwiązanie\n",
    "            print(\"compensation_of_next_word_power_matrix()\")\n",
    "            compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties)\n",
    "\n",
    "        print(\"koniec\")\n",
    "    \n",
    "\n",
    "\n",
    "def run_ant_algorithm(problem_properties, filename, method_of_probability_assignment=2):\n",
    "    random.seed(0)\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "\n",
    "\n",
    "        #zapisanie ważnych informacji w obiekcie klasy ProblemPropertiesClass\n",
    "        problem_properties.set_instance_info(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "\n",
    "        problem_properties.wages = set_starting_wages(problem_properties.word_len, problem_properties.k_set_starting_wages)\n",
    "\n",
    "\n",
    "        #wyznaczanie macierzy mocy prawdopodobieństwa następienia j-tego wyrazu po i-tym\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties)\n",
    "\n",
    "        #ustawienie wag prawdopodobieństwa dla rozpoczęcia tworzenia sekwencji przez dany wyraz\n",
    "        if(method_of_probability_assignment == 1):\n",
    "            generate_chance_for_first_word_1_with_numpy_tricks(problem_properties)\n",
    "        else:\n",
    "            generate_chance_for_first_word_2_with_numpy_tricks(problem_properties)\n",
    "\n",
    "        #wykonywanie poszczególnej iteracji; wykonywanie pętli, dopóki po określonej liczbie iteracji nie znajdzie się lepsze rozwiązanie\n",
    "        problem_properties.iterations_number = 0\n",
    "        while(problem_properties.iterations_number - problem_properties.iteration_with_the_best_sequence < problem_properties.iterations_number_limit):\n",
    "            problem_properties.prepare_iterations_vars()\n",
    "            problem_properties.iterations_number += 1\n",
    "\n",
    "\n",
    "            #tworzenie wynikowej sekwencji; powtarzanie prób uzyskania rozwiązania tyle razy, ile jest to określone parametrem 'problem_properties.attempts_number'\n",
    "            for indeks_of_attempt in range(problem_properties.attempts_number):\n",
    "                #utworzenie sekwencji\n",
    "                create_sequence(problem_properties, choose_next_word_with_numpy_tricks_4)\n",
    "\n",
    "                #zapamiętanie uzyskanej sekwencji\n",
    "                problem_properties.sequences.append(problem_properties.sequence)\n",
    "                \n",
    "\n",
    "\n",
    "            #nagrodzenie najlepszych rozwiązań przeprowadzając odpowiednie modyfikacje w macierzy wag prawdopodobieństw\n",
    "            reward_the_best_solutions_with_numpy_tricks(problem_properties)\n",
    "            \n",
    "            #zapamiętanie ewentualnego lepszego rozwiązania składającego się z większej ilości wyrazów\n",
    "            tmp_len = len(problem_properties.sequences[0])\n",
    "            if(problem_properties.best_sequence_len < tmp_len):\n",
    "                problem_properties.best_sequence_len = tmp_len\n",
    "                problem_properties.best_sequence = problem_properties.sequences[0]\n",
    "                problem_properties.iteration_with_the_best_sequence = problem_properties.iterations_number\n",
    "\n",
    "                    \n",
    "            #wywołanie funkcji zapamiętującej długości wszystkich uzyskanych sekwencji w danej iteracji\n",
    "            remember_sequences_lengths_with_numpy_tricks(problem_properties)\n",
    "            \n",
    "\n",
    "            #wygładzanie macierzy wag prawdopodobieństwa w celu zapobiegnięcia nadmiernemu zdominowaniu przez najlepsze rozwiązanie\n",
    "            compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<h1>Wywołanie algorytmu mrówkowego dla danego pliku i danych parametrów.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "problem_properties = ProblemPropertiesClass()\n",
    "\n",
    "#W konstruktorze klasy ProblemPropertiesClass zostały ustawione domyślne parametry, lecz można je również swobodnie zmieniać\n",
    "#problem_properties.iterations_number = 5\n",
    "#problem_properties.attempts_number = 10\n",
    "#problem_properties.part_of_the_best_sequences = 0.5\n",
    "#problem_properties.best_price_for_sequence = 3\n",
    "#problem_properties.k_set_starting_wages = 5\n",
    "#problem_properties.compensation_coef = 0.2\n",
    "#problem_properties.base_of_logarithm = 20\n",
    "\n",
    "filename = negative_random_filenames[2]\n",
    "#filename = negative_repetitions_filenames[0]\n",
    "#filename = positive_end_errors_filenames[0]\n",
    "#filename = positive_random_filenames[2]\n",
    "\n",
    "#run_ant_algorithm_constant_iteration_number_with_message(problem_properties, filename, method_of_probability_assignment=2)\n",
    "#run_ant_algorithm_constant_iteration_number(problem_properties, filename, method_of_probability_assignment=2)\n",
    "run_ant_algorithm_with_message(problem_properties, filename, method_of_probability_assignment=2)\n",
    "#run_ant_algorithm(problem_properties, filename, method_of_probability_assignment=2)\n",
    "\n",
    "print(\"Najlepsze rozwiązanie zostało złożone z \" + str(problem_properties.best_sequence_len - 1) + \" wyrazów.\")\n",
    "print(\"Znalezione zostało w \" + str(problem_properties.iteration_with_the_best_sequence) + \". iteracji.\")\n",
    "print(\"Ogółem wykonano \"+ str(problem_properties.iterations_number) + \" iteracji.\")\n",
    "print(problem_properties.best_sequence[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<h3>Próbna parametryzacja dla małego pliku w celu zrozumienia procesu</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_set_starting_wages_values = [1, 2, 3, 4, 5, 7, 9, 12, 15, 20]\n",
    "attempts_to_make_average = 3\n",
    "filename = 'instances\\\\positive_random_custom\\\\1.20+10'\n",
    "print(\"Plik: \" + str(filename))\n",
    "\n",
    "number_of_parameters_values = len(k_set_starting_wages_values)\n",
    "for indeks_of_parameter in range(number_of_parameters_values):\n",
    "    k_set_starting_wages_value = k_set_starting_wages_values[indeks_of_parameter]\n",
    "    \n",
    "    print(\"k_set_starting_wages_value = \" + str(k_set_starting_wages_value))\n",
    "    for attempt in range(attempts_to_make_average):\n",
    "        print(\"attempt = \" + str(attempt))\n",
    "        problem_properties = ProblemPropertiesClass()\n",
    "        problem_properties.k_set_starting_wages = k_set_starting_wages_value\n",
    "        \n",
    "        start_time = time.time()\n",
    "        run_ant_algorithm(problem_properties, filename, method_of_probability_assignment=2)\n",
    "        elapsed_time = time.time() - start_time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
