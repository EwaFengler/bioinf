{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "import re\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_PATH = path.dirname(path.abspath(\"__file__\"))  # gdyby nie działało, usuń cudzysłów\n",
    "INSTANCES_PATH = path.join(BASE_DIR_PATH, \"instances\")\n",
    "NEGATIVE_RANDOM_PATH = path.join(INSTANCES_PATH, \"negative_random\")\n",
    "NEGATIVE_REPETITIONS_PATH = path.join(INSTANCES_PATH, \"negative_repetitions\")\n",
    "POSITIVE_END_ERRORS_PATH = path.join(INSTANCES_PATH, \"positive_end_errors\")\n",
    "POSITIVE_RANDOM_PATH = path.join(INSTANCES_PATH, \"positive_random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_random_filenames = [path.join(NEGATIVE_RANDOM_PATH, f) for f in listdir(NEGATIVE_RANDOM_PATH) if path.isfile(path.join(NEGATIVE_RANDOM_PATH, f))]\n",
    "negative_repetitions_filenames = [path.join(NEGATIVE_REPETITIONS_PATH, f) for f in listdir(NEGATIVE_REPETITIONS_PATH) if path.isfile(path.join(NEGATIVE_REPETITIONS_PATH, f))]\n",
    "positive_end_errors_filenames = [path.join(POSITIVE_END_ERRORS_PATH, f) for f in listdir(POSITIVE_END_ERRORS_PATH) if path.isfile(path.join(POSITIVE_END_ERRORS_PATH, f))]\n",
    "positive_random_filenames = [path.join(POSITIVE_RANDOM_PATH, f) for f in listdir(POSITIVE_RANDOM_PATH) if path.isfile(path.join(POSITIVE_RANDOM_PATH, f))]\n",
    "\n",
    "selected_filenames = negative_random_filenames + negative_repetitions_filenames + positive_end_errors_filenames + positive_random_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in selected_filenames:\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "        \n",
    "        words = file.read().splitlines()\n",
    "        \n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        \n",
    "        print(\"nazwa pliku: \" + inst_name)\n",
    "        print(\"długość słowa: \" + str(word_len))\n",
    "        print(\"oryginalna liczba słów: \" + str(org_words_num))\n",
    "        print(\"oryginalna długość sekwencji: \"+ str(org_seq_len))\n",
    "        print(\"liczba błędów negatywnych: \" + str(neg_errors_number))\n",
    "        print(\"liczba błędów pozytywnych: \" + str(pos_errors_number))\n",
    "        print(words[:5])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Definicja klasy odpowiedzialnej za przechowywanie informacji dla danej instancji problemu.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemPropertiesClass:\n",
    "    def __init__(self):\n",
    "        self.words = []\n",
    "        self.word_len = 0\n",
    "        self.org_seq_len = 0\n",
    "        self.words_num = 0\n",
    "        \n",
    "        self.common_nucleotides_matrix = np.zeros((self.words_num + 1, self.words_num + 1), dtype=int)\n",
    "        self.wages = np.zeros(self.word_len)\n",
    "        self.next_word_power_matrix = np.zeros((self.words_num + 1, self.words_num + 1))\n",
    "        \n",
    "        self.avaible_words = np.ones(self.words_num + 1)\n",
    "        self.avaible_words_number = self.words_num\n",
    "        self.current_word = 0\n",
    "        self.current_length = 0\n",
    "    \n",
    "    def __init__(self, words, word_len, org_seq_len, words_num):\n",
    "        self.words = words[:]\n",
    "        self.word_len = word_len\n",
    "        self.org_seq_len = org_seq_len\n",
    "        self.words_num = words_num\n",
    "        \n",
    "        self.common_nucleotides_matrix = np.zeros((self.words_num + 1, self.words_num + 1), dtype=int)\n",
    "        self.wages = np.zeros(self.word_len)\n",
    "        self.next_word_power_matrix = np.zeros((self.words_num + 1, self.words_num + 1))\n",
    "        \n",
    "        self.avaible_words = np.ones(self.words_num + 1)\n",
    "        self.avaible_words_number = self.words_num\n",
    "        self.current_word = 0\n",
    "        self.current_length = 0\n",
    "        \n",
    "    \n",
    "    def prepare_general_vars(self):\n",
    "        self.common_nucleotides_matrix = np.zeros((self.words_num + 1, self.words_num + 1), dtype=int)\n",
    "        self.wages = np.zeros(self.word_len)\n",
    "        self.next_word_power_matrix = np.zeros((self.words_num + 1, self.words_num + 1))\n",
    "    \n",
    "    def prepare_attempts_vars(self):\n",
    "        self.avaible_words = np.ones(self.words_num + 1)    #definicja wektora określającego, czy i-ty wyraz jest dostępny\n",
    "        self.avaible_words_number = self.words_num           #definicja zmiennej zawierającej liczbę niewykorzystanych jeszcze wyrazów\n",
    "        self.current_word = 0                                #definicja zmiennej wskazującej ostatnio wybranego słowa -> słowo zerowe, czyli zaczynane jest tworzenie sekwencji\n",
    "        self.current_length = 0                              #definicja zmiennej zawierającej długość utworzonej dotychczas sekwencji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Wyznaczanie największej ilości znaków, na których sufiks pierwszego wyrazu pokrywa się z prefiksem drugiego wyrazu.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#funkcja zwraca maksymalną liczbę nukleotydów, na których zazębia się sufiks nucl1 z prefiksem nucl2\n",
    "#poszukiwanie poprzez coraz to mniejszą długość ciągu, porównywanie ciągów znak po znaku\n",
    "def common_nucleotides_max_number_full_iterating(nucl1, nucl2):\n",
    "    word_len = len(nucl1)\n",
    "    result = word_len - 1       #zmienna zawierająca końcowy wynik\n",
    "    \n",
    "    while(result > 0):          #badanie coraz to mniejszej możliwej długości wspólnego ciągu\n",
    "        i1 = word_len - result\n",
    "        i2 = 0\n",
    "        \n",
    "        while(i1 < word_len):              #porównanie nachodzących końcówek, znak po znaku\n",
    "            if(nucl1[i1] != nucl2[i2]):    #znaki się nie zgadzają\n",
    "                break\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "        \n",
    "        if(i1 == word_len):    #porównywanie ciągów zostało wykonane pozytywnie po wszystkich znakach\n",
    "            break\n",
    "        \n",
    "        result -= 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "#funkcja zwraca maksymalną liczbę nukleotydów, na których zazębia się sufiks nucl1 z prefiksem nucl2\n",
    "#poszukiwanie poprzez coraz to mniejszą długość ciągu, bezpośrednie porównywanie ciągów przy pomocy mechanizmu \"slicing\"\n",
    "def common_nucleotides_max_number_iterating_with_slicing(nucl1, nucl2):\n",
    "    word_len = len(nucl1)\n",
    "    result = word_len - 1       #zmienna zawierająca końcowy wynik\n",
    "    \n",
    "    while(result > 0):          #badanie coraz to mniejszej możliwej długości wspólnego ciągu\n",
    "        i1 = word_len - result\n",
    "        i2 = 0\n",
    "        \n",
    "        if(nucl1[-result:] == nucl2[:result]): #porównywanie ciągów przy pomocy mechanizmu \"slicing\"\n",
    "            break\n",
    "        \n",
    "        result -= 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Testowanie szybkości wyznaczania wspólego sufiksu nucl1 z prefiksem nucl2 ----------------#\n",
    "def speed_test_common_nucleotides_max_number(function, repetition):\n",
    "    print(\"Function testing in progress...\")\n",
    "    start_time = time.time()\n",
    "    filename = negative_random_filenames[0]\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "        \n",
    "        while(repetition > 0):\n",
    "            for i in range(words_num):\n",
    "                for j in range(words_num):\n",
    "                    if(i != j):\n",
    "                        number = function(words[i], words[j])\n",
    "            repetition -= 1\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"End of the function testing.\")\n",
    "    print(\"Time: \" + str(elapsed_time) + \"\\n\")\n",
    "\n",
    "#Wywołanie testowania funkcji\n",
    "#speed_test_common_nucleotides_max_number(common_nucleotides_max_number_full_iterating, 10)            #repetition=10 Time: 13.98816466331482\n",
    "#speed_test_common_nucleotides_max_number(common_nucleotides_max_number_iterating_with_slicing, 10)    #repetition=10 Time: 16.22281813621521"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Wyznaczanie macierzy zawierającej długości wspólnych sufiksów-prefiksów wszystkich par słów.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_common_nucleotides_matrix_full_iterating(problem_properties):\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "            for j in range(1, problem_properties.words_num + 1):\n",
    "                if(i != j):\n",
    "                    problem_properties.common_nucleotides_matrix[i, j] = common_nucleotides_max_number_full_iterating(problem_properties.words[i], problem_properties.words[j])\n",
    "                else:\n",
    "                    problem_properties.common_nucleotides_matrix[i, i] = 0\n",
    "\n",
    "def generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number(problem_properties, i, j):\n",
    "    if(i != j):\n",
    "        return common_nucleotides_max_number_full_iterating(problem_properties.words[i], problem_properties.words[j])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def generate_common_nucleotides_matrix_with_numpy_tricks(problem_properties):\n",
    "    index_of_column = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1), dtype=int)\n",
    "    index_of_row = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1), dtype=int)\n",
    "\n",
    "    index_of_column[:] = np.arange(problem_properties.words_num + 1)\n",
    "    index_of_row = index_of_column.transpose()\n",
    "\n",
    "    vectorized_generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number = np.vectorize(generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number)\n",
    "    problem_properties.common_nucleotides_matrix[1:, 1:] = vectorized_generate_common_nucleotides_matrix_with_numpy_tricks_common_nucleotides_max_number(problem_properties, index_of_row[1:, 1:], index_of_column[1:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Testowanie szybkości wyznaczania macierzy zawierającej długości wspólnych brzegów wszystkich par słów ----------------#\n",
    "def speed_test_generate_common_nucleotides_matrix(function, repetition):\n",
    "    print(\"Preparing required variables...\")\n",
    "    filename = negative_random_filenames[0]\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "        \n",
    "        \n",
    "        problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "        \n",
    "        \n",
    "        print(\"Function testing in progress...\")\n",
    "        start_time = time.time()\n",
    "        while(repetition > 0):\n",
    "            function(problem_properties)\n",
    "            repetition -= 1\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"End of the function testing.\")\n",
    "        print(\"Time: \" + str(elapsed_time) + \"\\n\\n\")\n",
    "\n",
    "#Wywołanie testowania funkcji\n",
    "#speed_test_generate_common_nucleotides_matrix(generate_common_nucleotides_matrix_full_iterating, 10)       #repetition=10 Time: 7.415224313735962\n",
    "#speed_test_generate_common_nucleotides_matrix(generate_common_nucleotides_matrix_with_numpy_tricks, 10)       #repetition=10 Time: 7.34582257270813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Sprawdzanie poprawności wyznaczania macierzy zawierającej długości wspólnych brzegów wszystkich par słów ----------------#\n",
    "print(\"Preparing required variables...\")\n",
    "filename = negative_random_filenames[0]\n",
    "with open(filename, 'r') as file:\n",
    "    inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "    word_len = len(words[0])\n",
    "    org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "    org_seq_len = org_words_num + word_len - 1\n",
    "    neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "    neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "    pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "    pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "    words_num = len(words)\n",
    "\n",
    "    #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "    words = [\"Poczatek\"] + words\n",
    "    \n",
    "    \n",
    "    problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "    \n",
    "    \n",
    "    print(\"Function testing in progress...\")\n",
    "    generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "    matrix1 = np.copy(problem_properties.common_nucleotides_matrix)\n",
    "    generate_common_nucleotides_matrix_with_numpy_tricks(problem_properties)\n",
    "    matrix2 = np.copy(problem_properties.common_nucleotides_matrix)\n",
    "    \n",
    "    print(matrix2 - matrix1)\n",
    "    print(np.sum(matrix2 - matrix1))\n",
    "\n",
    "    print(\"End of the function testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Wyznaczanie wektora bazowych wartości wag prawdopodobieństwa, które są obliczane na podstawie długości wspólnego sufiksu-prefiksu wyrazów.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_starting_wages(n, k):\n",
    "    result = np.zeros(n)\n",
    "    n -= 1\n",
    "    result[n] = 1.0\n",
    "    while(n > 0):\n",
    "        n -= 1\n",
    "        result[n] = result[n + 1] / k\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Wyznaczanie wag prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego wyrazu.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#waga przyznawana jest na podstawie długości wspólnego sufiksu-prefiksu słowa i-tego i j-tego\n",
    "def generate_next_word_power_matrix_1_full_iterating(problem_properties):\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            problem_properties.next_word_power_matrix[i, j] = problem_properties.wages[ problem_properties.common_nucleotides_matrix[i, j] ]\n",
    "            \n",
    "            \n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#waga przyznawana jest na podstawie długości wspólnego sufiksu-prefiksu słowa i-tego i j-tego\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties):\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    problem_properties.next_word_power_matrix[1:, 1:] = problem_properties.wages[ problem_properties.common_nucleotides_matrix[1:, 1:] ]\n",
    "    #next_word_power_matrix = wages[ common_nucleotides_matrix ]   #ta linia nie modyfikuje globalnie macierzny next_word_power_matrix, będzie trzeba pobawić się w przekazywanie argumentów\n",
    "\n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "def generate_next_word_power_matrix_2_full_iterating(problem_properties):\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            occurrence_counter[ problem_properties.common_nucleotides_matrix[i, j] ] += 1\n",
    "        \n",
    "        #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "        current_wages = np.copy(problem_properties.wages)\n",
    "        for j in range(problem_properties.word_len):\n",
    "            if(occurrence_counter[j] != 0):\n",
    "                current_wages[j] /= occurrence_counter[j]\n",
    "        \n",
    "        #przydzielenie wag dla konkretnych połączeń wyrazów\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            problem_properties.next_word_power_matrix[i, j] = current_wages[ problem_properties.common_nucleotides_matrix[i, j] ]\n",
    "\n",
    "            \n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_2_with_numpy_tricks_1(problem_properties):\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "        unique, counts = np.unique(problem_properties.common_nucleotides_matrix[i, 1:], return_counts=True)\n",
    "        occurrence_counter[unique] = counts\n",
    "        \n",
    "        #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "        current_wages = np.copy(problem_properties.wages)\n",
    "        occurrence_counter[occurrence_counter == 0] = 1\n",
    "        current_wages /= occurrence_counter\n",
    "        \n",
    "        #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "        problem_properties.next_word_power_matrix[i, 1:] = current_wages[ problem_properties.common_nucleotides_matrix[i, 1:] ]\n",
    "\n",
    "            \n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties):\n",
    "    occurrence_counter = np.zeros((problem_properties.words_num + 1, problem_properties.word_len))\n",
    "    \n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        unique, counts = np.unique(problem_properties.common_nucleotides_matrix[i, 1:], return_counts=True)\n",
    "        occurrence_counter[i, unique] = counts\n",
    "        \n",
    "    occurrence_counter[occurrence_counter == 0] = 1\n",
    "        \n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.zeros((problem_properties.words_num+1, problem_properties.word_len))\n",
    "    current_wages[:] = problem_properties.wages\n",
    "    current_wages /= occurrence_counter\n",
    "    \n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for i in range(1, problem_properties.words_num + 1):\n",
    "        problem_properties.next_word_power_matrix[i, 1:] = current_wages[i, problem_properties.common_nucleotides_matrix[i, 1:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Testowanie szybkości wyznaczania wag prawdopodobień dla wyboru j-tego wyrazu po wybranym już i-tym wyrazie ----------------#\n",
    "def speed_test_generate_next_word_power_matrix(function, repetition):\n",
    "    print(\"Preparing required variables...\")\n",
    "    filename = negative_random_filenames[0]\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "        \n",
    "        \n",
    "        problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "        \n",
    "        \n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "\n",
    "        problem_properties.wages = set_starting_wages(problem_properties.word_len, 2)\n",
    "        \n",
    "        \n",
    "        print(\"Function testing in progress...\")\n",
    "        start_time = time.time()\n",
    "        while(repetition > 0):\n",
    "            function(problem_properties)\n",
    "            repetition -= 1\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"End of the function testing.\")\n",
    "        print(\"Time: \" + str(elapsed_time) + \"\\n\\n\")\n",
    "\n",
    "#Wywołanie testowania funkcji\n",
    "#speed_test_generate_next_word_power_matrix(generate_next_word_power_matrix_1_full_iterating, 100)       #repetition=100 Time: 12.014138460159302\n",
    "#speed_test_generate_next_word_power_matrix(generate_next_word_power_matrix_2_full_iterating, 100)       #repetition=100 Time: 28.95266628265381\n",
    "#speed_test_generate_next_word_power_matrix(generate_next_word_power_matrix_1_with_numpy_tricks, 100)    #repetition=100 Time: 0.24304628372192383\n",
    "#speed_test_generate_next_word_power_matrix(generate_next_word_power_matrix_2_with_numpy_tricks_1, 100)  #repetition=100 Time: 2.4654126167297363\n",
    "#speed_test_generate_next_word_power_matrix(generate_next_word_power_matrix_2_with_numpy_tricks_2, 100)  #repetition=100 Time: 1.8123927116394043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Sprawdzanie poprawności wyznaczania wag prawdopodobień dla wyboru j-tego wyrazu po wybranym już i-tym wyrazie ----------------#\n",
    "print(\"Preparing required variables...\")\n",
    "filename = negative_random_filenames[0]\n",
    "with open(filename, 'r') as file:\n",
    "    inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "    word_len = len(words[0])\n",
    "    org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "    org_seq_len = org_words_num + word_len - 1\n",
    "    neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "    neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "    pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "    pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "    words_num = len(words)\n",
    "\n",
    "    #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "    words = [\"Poczatek\"] + words\n",
    "        \n",
    "        \n",
    "    problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "    #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "    generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "\n",
    "    problem_properties.wages = set_starting_wages(problem_properties.word_len, 2)\n",
    "\n",
    "\n",
    "    print(\"Function testing in progress...\")\n",
    "    #generate_next_word_power_matrix_1_full_iterating(problem_properties)\n",
    "    generate_next_word_power_matrix_2_full_iterating(problem_properties)\n",
    "    vector1 = np.copy(problem_properties.next_word_power_matrix)\n",
    "    #generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties)\n",
    "    #generate_next_word_power_matrix_2_with_numpy_tricks_1(problem_properties)\n",
    "    generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties)\n",
    "    vector2 = np.copy(problem_properties.next_word_power_matrix)\n",
    "    \n",
    "    print(vector2 - vector1)\n",
    "    print(np.sum(vector2 - vector1))\n",
    "\n",
    "    print(\"End of the function testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Wyznaczenie wag prawdopodobieństwa dla wyboru wyrazu rozpoczynającego sekwencje.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja ustawia równe szanse wyboru słowa rozpoczynającego sekwencje\n",
    "def generate_chance_for_first_word(problem_properties):\n",
    "    problem_properties.next_word_power_matrix[0, 1:] = 1;\n",
    "\n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "def generate_chance_for_first_word_1_full_iterating(problem_properties):\n",
    "    max_common_nucleotides = np.zeros(problem_properties.words_num + 1, dtype=int)\n",
    "\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[1, j]\n",
    "        for i in range(2, problem_properties.words_num + 1):\n",
    "            if(max_common_nucleotides[j] < problem_properties.common_nucleotides_matrix[i, j]):\n",
    "                max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[i, j]\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        problem_properties.next_word_power_matrix[0, j] = problem_properties.wages[ problem_properties.word_len - 1 - max_common_nucleotides[j] ]\n",
    "\n",
    "        \n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_chance_for_first_word_1_with_numpy_tricks(problem_properties):\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    max_common_nucleotides = problem_properties.common_nucleotides_matrix.max(0)\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    problem_properties.next_word_power_matrix[0] = problem_properties.wages[ problem_properties.word_len - 1 - max_common_nucleotides]\n",
    "    \n",
    "    \n",
    "\n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#określona już waga jest równomiernie rozdzielona na wyrazy o poszczególnej długości maksymalnego zazębienia\n",
    "def generate_chance_for_first_word_2_full_iterating(problem_properties):\n",
    "    max_common_nucleotides = np.zeros(problem_properties.words_num + 1, dtype=int)\n",
    "\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[1, j]\n",
    "        for i in range(2, problem_properties.words_num + 1):\n",
    "            if(max_common_nucleotides[j] < problem_properties.common_nucleotides_matrix[i, j]):\n",
    "                max_common_nucleotides[j] = problem_properties.common_nucleotides_matrix[i, j]\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag, waga jest równomiernie rozdizelona\n",
    "    occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        occurrence_counter[ max_common_nucleotides[j] ] += 1\n",
    "\n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.flip(np.copy(problem_properties.wages))\n",
    "    for j in range(problem_properties.word_len):\n",
    "        if(occurrence_counter[j] != 0):\n",
    "            current_wages[j] /= occurrence_counter[j]\n",
    "\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        problem_properties.next_word_power_matrix[0, j] = current_wages[ max_common_nucleotides[j] ]\n",
    "        \n",
    "        \n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#określona już waga jest równomiernie rozdzielona na wyrazy o poszczególnej długości maksymalnego zazębienia\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_chance_for_first_word_2_with_numpy_tricks(problem_properties):\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    max_common_nucleotides = problem_properties.common_nucleotides_matrix.max(0)\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag, waga jest równomiernie rozdizelona\n",
    "    occurrence_counter = np.zeros(problem_properties.word_len)\n",
    "    unique, counts = np.unique(max_common_nucleotides[1:], return_counts=True)\n",
    "    occurrence_counter[unique] = counts\n",
    "\n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.flip(np.copy(problem_properties.wages))\n",
    "    occurrence_counter[occurrence_counter == 0] = 1\n",
    "    current_wages /= occurrence_counter\n",
    "\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    problem_properties.next_word_power_matrix[0, 1:] = current_wages[ max_common_nucleotides[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Testowanie szybkości wyznaczania wag prawdopodobień dla wyboru pierwszego wyrazu w sekwencji ----------------#\n",
    "def speed_test_generate_chance_for_first_word(function, repetition):\n",
    "    print(\"Preparing required variables...\")\n",
    "    filename = negative_random_filenames[0]\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "        \n",
    "        \n",
    "        problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "\n",
    "        problem_properties.wages = set_starting_wages(problem_properties.word_len, 2)\n",
    "        \n",
    "        \n",
    "        print(\"Function testing in progress...\")\n",
    "        start_time = time.time()\n",
    "        while(repetition > 0):\n",
    "            function(problem_properties)\n",
    "            repetition -= 1\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"End of the function testing.\")\n",
    "        print(\"Time: \" + str(elapsed_time) + \"\\n\\n\")\n",
    "\n",
    "#Wywołanie testowania funkcji\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word, 100)                     #repetition=100 Time: 0.0\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word_1_full_iterating, 100)    #repetition=100 Time: 6.527872323989868\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word_2_full_iterating, 100)    #repetition=100 Time: 6.567286014556885\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word_1_with_numpy_tricks, 100) #repetition=100 Time: 0.017966747283935547\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word_2_with_numpy_tricks, 100) #repetition=100 Time: 0.02245807647705078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Sprawdzanie poprawności wyznaczania wag prawdopodobień dla wyboru pierwszego wyrazu w sekwencji ----------------#\n",
    "print(\"Preparing required variables...\")\n",
    "filename = negative_random_filenames[0]\n",
    "with open(filename, 'r') as file:\n",
    "    inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "    word_len = len(words[0])\n",
    "    org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "    org_seq_len = org_words_num + word_len - 1\n",
    "    neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "    neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "    pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "    pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "    words_num = len(words)\n",
    "\n",
    "    #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "    words = [\"Poczatek\"] + words\n",
    "        \n",
    "        \n",
    "    problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "    #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "    generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "\n",
    "    problem_properties.wages = set_starting_wages(problem_properties.word_len, 2)\n",
    "\n",
    "\n",
    "    print(\"Function testing in progress...\")\n",
    "    #generate_chance_for_first_word_1_full_iterating(problem_properties)\n",
    "    generate_chance_for_first_word_2_full_iterating(problem_properties)\n",
    "    vector1 = np.copy(problem_properties.next_word_power_matrix[0])\n",
    "    #generate_chance_for_first_word_1_with_numpy_tricks(problem_properties)\n",
    "    generate_chance_for_first_word_2_with_numpy_tricks(problem_properties)\n",
    "    vector2 = np.copy(problem_properties.next_word_power_matrix[0])\n",
    "    \n",
    "    print(vector2 - vector1)\n",
    "\n",
    "\n",
    "    print(\"End of the function testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja wybiera kolejny wyraz dla tworzonego ciągu\n",
    "def choose_next_word(problem_properties):\n",
    "    #print(\"avaible words przed: \" + str(problem_properties.avaible_words_number))\n",
    "    #wybranie odpowiednich wektorów z macierzy, które przechowują dane dla ostatnio wybranego słowa\n",
    "    common_nucleotides_vector = problem_properties.common_nucleotides_matrix[problem_properties.current_word]\n",
    "    next_word_power_vector = problem_properties.next_word_power_matrix[problem_properties.current_word]\n",
    "    \n",
    "    #jeśli obecna długość wynikowego ciągu zwiększona o pełną długość kolejnego słowa przekracza ograniczającą długość ciągu znaków,\n",
    "    #to trzeba wykluczyć możliwość wyboru kolejnego słowa, które by to za bardzo zwiększyła długość wynikowej sekwencji\n",
    "    #print(str(problem_properties.current_length) + \" + \" + str(problem_properties.word_len) + \" > \" + str(problem_properties.org_seq_len))\n",
    "    if(problem_properties.current_length + problem_properties.word_len > problem_properties.org_seq_len):\n",
    "        for j in range(1, problem_properties.words_num + 1):\n",
    "            if((problem_properties.avaible_words[j]) and (problem_properties.current_length + (problem_properties.word_len - common_nucleotides_vector[j]) > problem_properties.org_seq_len)):\n",
    "                problem_properties.avaible_words[j] = 0\n",
    "                problem_properties.avaible_words_number -= 1\n",
    "        \n",
    "        #print(\"Juz prawie koniec - mozna dopasowac jeszcze \" + str(problem_properties.avaible_words_number) + \" slow\")\n",
    "    \n",
    "    #nie ma już dostępnych słów do doklejenia\n",
    "    if(not(problem_properties.avaible_words_number)):\n",
    "        return -1\n",
    "    \n",
    "    #obliczenie sumy mocy prawdopodobieństwa wyboru dla dostępnych słów\n",
    "    sum_of_probability = 0\n",
    "    for j in range(1, problem_properties.words_num + 1):\n",
    "        if(problem_properties.avaible_words[j]):\n",
    "            sum_of_probability += next_word_power_vector[j]\n",
    "\n",
    "            \n",
    "    \"\"\"#print(str(max_sum) + \" < \" + str(sum_of_probability))\n",
    "    if(max_sum < sum_of_probability):\n",
    "        max_sum = sum_of_probability\n",
    "        print(\"sum_of_probability = \" + str(sum_of_probability))\"\"\"\n",
    "    \n",
    "    #realizacja wyboru zgodnie z gęstością prawdopodobieństwa - wybór punktu na odcinku złożonego z sumy mocy prawdopodobieństwa dostępnych połączeń\n",
    "    point_in_range_of_sum_of_probability = random.uniform(0, sum_of_probability)\n",
    "    \n",
    "    #odnalezienie wybranego kolejnego słowa, które zostało wskazane przez wylosowany punkt na odcinku\n",
    "    j = 1\n",
    "    while(not(problem_properties.avaible_words[j])):\n",
    "        j += 1\n",
    "    \n",
    "    current_sum_of_probability = next_word_power_vector[j]\n",
    "    while(point_in_range_of_sum_of_probability > current_sum_of_probability):\n",
    "        j += 1\n",
    "        while(not(problem_properties.avaible_words[j])):\n",
    "            j += 1\n",
    "        current_sum_of_probability += next_word_power_vector[j]\n",
    "    \n",
    "    #print(\"avaible words po: \" + str(problem_properties.avaible_words_number))\n",
    "    \n",
    "    return j\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Przeprowadzanie wygładzania dominujących wartości w macierzy wag prawdopodobieństwa.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja dokonuje wygładzania wartości wag prawdopodobieństw -> zmienia szanse wyboru na bardziej równe, zachowująć jednocześnie porządek preferencji\n",
    "def compensation_of_next_word_power_matrix_full_iterating(problem_properties):\n",
    "    compensation_coef = 0.98\n",
    "    base_of_logarithm = 2\n",
    "    \n",
    "    for i in range(problem_properties.words_num + 1):\n",
    "        max_value = max(problem_properties.next_word_power_matrix[i])\n",
    "        sum_value = sum(problem_properties.next_word_power_matrix[i])\n",
    "        \n",
    "        #jeśli maksymalna wartość zdecydowanie się wyróżnia, to należy złagodzić dysproporcje między wagami prawdopodobieństw\n",
    "        #print(\"max_value = \" + str(max_value))\n",
    "        #print(\"sum_value * compensation_coef = \" + str(sum_value * compensation_coef))\n",
    "        if(max_value > sum_value * compensation_coef):\n",
    "            #poszukiwanie minimalnej wartości wagi prawdopodobieństwa nie mniejszej niż wartość 1. Wartość ta jest potrzebna do wzoru wygładzającego\n",
    "            min_value = max_value\n",
    "            for j in range(problem_properties.words_num + 1):\n",
    "                if((problem_properties.next_word_power_matrix[i, j] >= 1) and (min_value > problem_properties.next_word_power_matrix[i, j])):\n",
    "                    min_value = problem_properties.next_word_power_matrix[i, j]\n",
    "            \n",
    "            #wygładzanie wag większych niż wartość 1\n",
    "            for j in range(problem_properties.words_num + 1):\n",
    "                if(min_value < problem_properties.next_word_power_matrix[i, j]):\n",
    "                    problem_properties.next_word_power_matrix[i, j] = min_value * (1 + math.log(problem_properties.next_word_power_matrix[i, j] / min_value, base_of_logarithm))\n",
    "\n",
    "#funkcja dokonuje wygładzania wartości wag prawdopodobieństw -> zmienia szanse wyboru na bardziej równe, zachowująć jednocześnie porządek preferencji\n",
    "#operacja zmiany wag w danym wierszu została tutaj zwektoryzowana\n",
    "def compensation_of_next_word_power_matrix_with_numpy_tricks_1(problem_properties):\n",
    "    compensation_coef = 0.98\n",
    "    base_of_logarithm = 2\n",
    "    \n",
    "    for i in range(problem_properties.words_num + 1):\n",
    "        max_value = max(problem_properties.next_word_power_matrix[i])\n",
    "        sum_value = sum(problem_properties.next_word_power_matrix[i])\n",
    "        \n",
    "        #jeśli maksymalna wartość zdecydowanie się wyróżnia, to należy złagodzić dysproporcje między wagami prawdopodobieństw\n",
    "        #print(\"max_value = \" + str(max_value))\n",
    "        #print(\"sum_value * compensation_coef = \" + str(sum_value * compensation_coef))\n",
    "        if(max_value > sum_value * compensation_coef):\n",
    "            #poszukiwanie minimalnej wartości wagi prawdopodobieństwa nie mniejszej niż wartość 1. Wartość ta jest potrzebna do wzoru wygładzającego\n",
    "            min_value = min(problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] >= 1])\n",
    "            \n",
    "            #wygładzanie wag większych niż wartość 1\n",
    "            problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] > min_value] = min_value * (1 + np.log(problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] > min_value] / min_value) / np.log(base_of_logarithm))\n",
    "\n",
    "#funkcja dokonuje wygładzania wartości wag prawdopodobieństw -> zmienia szanse wyboru na bardziej równe, zachowująć jednocześnie porządek preferencji\n",
    "#cała procedura została zwektoryzowana\n",
    "def compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties):\n",
    "    compensation_coef = 0.98\n",
    "    base_of_logarithm = 2\n",
    "    \n",
    "    max_value = np.max(problem_properties.next_word_power_matrix, axis=1)\n",
    "    sum_value = np.sum(problem_properties.next_word_power_matrix, axis=1)\n",
    "    \n",
    "    #odwzorowanie maksymalnych wartości wierszy na całą macierz\n",
    "    max_value_matrix = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1))\n",
    "    max_value_matrix[:] = max_value\n",
    "    max_value_matrix = max_value_matrix.transpose()\n",
    "\n",
    "    #odwzorowanie sumy wartości wierszy na całą macierz\n",
    "    sum_value_matrix = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1))\n",
    "    sum_value_matrix[:] = sum_value\n",
    "    sum_value_matrix = sum_value_matrix.transpose()\n",
    "\n",
    "    #wskazanie wierszy w macierzy, w których trzeba wykonać wygładzanie\n",
    "    mask_row = max_value_matrix > sum_value_matrix * compensation_coef\n",
    "\n",
    "    #przygotowanie kopii next_word_power_matrix, którą będzie trzeba zmodyfikować w celu odnalezienia minimalnej wartości większej niż 1 dla każdego wiersza\n",
    "    tmp_next_word_power_matrix = np.copy(problem_properties.next_word_power_matrix)\n",
    "    mask_tmp = tmp_next_word_power_matrix < 1\n",
    "    tmp_next_word_power_matrix[mask_tmp] = max_value_matrix[mask_tmp]\n",
    "\n",
    "    #wyznaczenie i odwzorowanie na całą macierz minimalnej wartości większej niż 1 dla każdego wiersza\n",
    "    min_value = np.min(tmp_next_word_power_matrix, axis=1)\n",
    "    min_value_matrix = np.zeros((problem_properties.words_num + 1, problem_properties.words_num + 1))\n",
    "    min_value_matrix[:] = min_value\n",
    "    min_value_matrix = min_value_matrix.transpose()\n",
    "\n",
    "    #wskazanie elementów, które należy zmodyfikować\n",
    "    mask_final = ((problem_properties.next_word_power_matrix >= min_value_matrix) * (mask_row))\n",
    "\n",
    "    #wykonanie faktycznego wygładzania dominujących wartości w problem_properties.next_word_power_matrix\n",
    "    min_value_vector = min_value_matrix[mask_final]\n",
    "    problem_properties.next_word_power_matrix[mask_final] = min_value_vector * (1 + np.log(problem_properties.next_word_power_matrix[mask_final] / min_value_vector) / np.log(base_of_logarithm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Testowanie szybkości wygładzania wag ----------------#\n",
    "def speed_test_compensation_of_next_word_power_matrix(function, repetition, force_compensation):\n",
    "    print(\"Preparing required variables...\")\n",
    "    filename = negative_random_filenames[0]\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "        \n",
    "        \n",
    "        problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "\n",
    "\n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "\n",
    "        problem_properties.wages = set_starting_wages(problem_properties.word_len, 2)\n",
    "\n",
    "\n",
    "        generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties)\n",
    "        generate_chance_for_first_word_1_with_numpy_tricks(problem_properties)\n",
    "        \n",
    "        print(\"Function testing in progress...\")\n",
    "        start_time = time.time()\n",
    "        while(repetition > 0):\n",
    "            if(force_compensation):\n",
    "                problem_properties.next_word_power_matrix[:, 2] = 1000000\n",
    "            function(problem_properties)\n",
    "            repetition -= 1\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"End of the function testing.\")\n",
    "        print(\"Time: \" + str(elapsed_time) + \"\\n\\n\")\n",
    "\n",
    "#Wywołanie testowania funkcji\n",
    "#speed_test_compensation_of_next_word_power_matrix(compensation_of_next_word_power_matrix_full_iterating, 10, force_compensation=False)       #repetition=10 Time: 0.30295610427856445\n",
    "#speed_test_compensation_of_next_word_power_matrix(compensation_of_next_word_power_matrix_full_iterating, 10, force_compensation=True)        #repetition=10 Time: 1.3494906425476074\n",
    "#speed_test_compensation_of_next_word_power_matrix(compensation_of_next_word_power_matrix_with_numpy_tricks_1, 10, force_compensation=False)  #repetition=10 Time: 0.3110346794128418\n",
    "#speed_test_compensation_of_next_word_power_matrix(compensation_of_next_word_power_matrix_with_numpy_tricks_1, 10, force_compensation=True)   #repetition=10 Time: 0.45663905143737793\n",
    "#speed_test_compensation_of_next_word_power_matrix(compensation_of_next_word_power_matrix_with_numpy_tricks_2, 10, force_compensation=False)  #repetition=10 Time: 0.08384537696838379\n",
    "#speed_test_compensation_of_next_word_power_matrix(compensation_of_next_word_power_matrix_with_numpy_tricks_2, 10, force_compensation=True)   #repetition=10 Time: 0.08833527565002441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Sprawdzanie poprawności wygładzania wag ----------------#\n",
    "print(\"Preparing required variables...\")\n",
    "filename = negative_random_filenames[0]\n",
    "with open(filename, 'r') as file:\n",
    "    inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "    word_len = len(words[0])\n",
    "    org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "    org_seq_len = org_words_num + word_len - 1\n",
    "    neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "    neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "    pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "    pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "    words_num = len(words)\n",
    "\n",
    "    #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "    words = [\"Poczatek\"] + words\n",
    "        \n",
    "        \n",
    "    problem_properties1 = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "    problem_properties2 = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "    \n",
    "\n",
    "\n",
    "    #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "    generate_common_nucleotides_matrix_full_iterating(problem_properties1)\n",
    "    generate_common_nucleotides_matrix_full_iterating(problem_properties2)\n",
    "\n",
    "    problem_properties1.wages = set_starting_wages(problem_properties1.word_len, 2)\n",
    "    problem_properties2.wages = set_starting_wages(problem_properties2.word_len, 2)\n",
    "\n",
    "\n",
    "    generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties1)\n",
    "    generate_chance_for_first_word_2_with_numpy_tricks(problem_properties1)\n",
    "    problem_properties1.next_word_power_matrix[:, 2] = 1000000\n",
    "    \n",
    "    generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties2)\n",
    "    generate_chance_for_first_word_2_with_numpy_tricks(problem_properties2)\n",
    "    problem_properties2.next_word_power_matrix[:, 2] = 1000000\n",
    "    \n",
    "    \n",
    "    print(\"Function testing in progress...\")\n",
    "    compensation_of_next_word_power_matrix_full_iterating(problem_properties1)\n",
    "    matrix1 = np.copy(problem_properties1.next_word_power_matrix)\n",
    "    print(problem_properties1.next_word_power_matrix)\n",
    "    \n",
    "    #compensation_of_next_word_power_matrix_with_numpy_tricks_1(problem_properties2)\n",
    "    compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties2)\n",
    "    matrix2 = np.copy(problem_properties2.next_word_power_matrix)\n",
    "    print(problem_properties2.next_word_power_matrix)\n",
    "    \n",
    "    print(matrix2 - matrix1)\n",
    "    print(\"sum: \" + str(np.sum(matrix2 - matrix1)))\n",
    "\n",
    "\n",
    "    print(\"End of the function testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<h1>Główny kod wykonujący obliczenia zgodnie z algorytmem mrówkowym</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "filename = negative_random_filenames[0]\n",
    "with open(filename, 'r') as file:\n",
    "    inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "    word_len = len(words[0])\n",
    "    org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "    org_seq_len = org_words_num + word_len - 1\n",
    "    neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "    neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "    pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "    pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "    words_num = len(words)\n",
    "\n",
    "    print(\"nazwa pliku: \" + inst_name)\n",
    "    print(\"długość słowa: \" + str(word_len))\n",
    "    print(\"oryginalna liczba słów: \" + str(org_words_num))\n",
    "    print(\"oryginalna długość sekwencji: \"+ str(org_seq_len))\n",
    "    print(\"liczba błędów negatywnych: \" + str(neg_errors_number))\n",
    "    print(\"liczba błędów pozytywnych: \" + str(pos_errors_number))\n",
    "    print(\"liczba oligonukleotydów: \" + str(words_num))\n",
    "    \n",
    "    #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "    words = [\"Poczatek\"] + words\n",
    "    print(words[:5])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    #zapisanie ważnych informacji w obiekcie klasy ProblemPropertiesClass\n",
    "    problem_properties = ProblemPropertiesClass(words, word_len, org_seq_len, words_num)\n",
    "    \n",
    "    \n",
    "    #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "    print(\"common_nucleotides_matrix\")\n",
    "    generate_common_nucleotides_matrix_full_iterating(problem_properties)\n",
    "    #print(common_nucleotides_matrix[0, :])\n",
    "    \n",
    "    print(\"set_starting_wages()\")\n",
    "    problem_properties.wages = set_starting_wages(problem_properties.word_len, 2)\n",
    "    #print(wages)\n",
    "    \n",
    "    \n",
    "    #wyznaczanie macierzy mocy prawdopodobieństwa następienia j-tego wyrazu po i-tym\n",
    "    #generate_next_word_power_matrix_1_full_iterating(problem_properties)\n",
    "    #generate_next_word_power_matrix_2_full_iterating(problem_properties)\n",
    "    #print(\"generate_next_word_power_matrix_1_with_numpy_tricks()\")\n",
    "    #generate_next_word_power_matrix_1_with_numpy_tricks(problem_properties)\n",
    "    #print(\"generate_next_word_power_matrix_2_with_numpy_tricks_1()\")\n",
    "    #generate_next_word_power_matrix_2_with_numpy_tricks_1(problem_properties)\n",
    "    print(\"generate_next_word_power_matrix_2_with_numpy_tricks_2()\")\n",
    "    generate_next_word_power_matrix_2_with_numpy_tricks_2(problem_properties)\n",
    "    \n",
    "    #ustawienie wag prawdopodobieństwa dla rozpoczęcia tworzenia sekwencji przez dany wyraz\n",
    "    #print(\"generate_chance_for_first_word()\")\n",
    "    #generate_chance_for_first_word(problem_properties)\n",
    "    #print(\"generate_chance_for_first_word_1_with_numpy_tricks()\")\n",
    "    #generate_chance_for_first_word_1_with_numpy_tricks(problem_properties)\n",
    "    print(\"generate_chance_for_first_word_2_with_numpy_tricks()\")\n",
    "    generate_chance_for_first_word_2_with_numpy_tricks(problem_properties)\n",
    "    \n",
    "    \n",
    "    iterations_number = 100    #definicja zmiennej określającej ile iteracji będzie trwał algorytm mrówkowy\n",
    "    #max_w_macierzy = 0\n",
    "    \n",
    "    #wykonywanie poszczególnej iteracji; wykonywanie pętli tyle razy, ile jest zadeklarowanych iteracji do wykonania\n",
    "    for indeks_of_iteration in range(iterations_number):\n",
    "        attempts_number = 100  #definicja zmiennej określającej ile razy dokonywane jest budowanie sekwencji w jednej iteracji\n",
    "        sequences = []\n",
    "        \n",
    "        \n",
    "        #tworzenie wynikowej sekwencji; powtarzanie prób uzyskania rozwiązania tyle razy, ile jest to określone parametrem 'attempts_number'\n",
    "        print(\"\\nIteracja \" + str(indeks_of_iteration) + \":\\t\\nTrwa wykonywanie wszystkich \" + str(attempts_number) + \" prób utworzenia wynikowej sekwencji.\")\n",
    "        for indeks_of_attempt in range(attempts_number):\n",
    "            problem_properties.prepare_attempts_vars()\n",
    "            sequence = []\n",
    "            \n",
    "            problem_properties.avaible_words[0] = 0        #odznaczenie użycia już zerowego słowa ('X')\n",
    "            problem_properties.current_word = 0            #definicja zmiennej wskazującej ostatnio wybranego słowa -> słowo zerowe, czyli zaczynane jest tworzenie sekwencji\n",
    "            sequence.append(problem_properties.current_word)\n",
    "            \n",
    "            #nieustannie wykonująca się pętla - zostanie przerwana, gdy nie będzie już możliwości doczepienia słowa przy ograniczeniu ilości znaków w wynikowym ciągu\n",
    "            while(True):\n",
    "                next_word = choose_next_word(problem_properties)\n",
    "                #print(\"Wybrane slowo: \" + str(next_word))\n",
    "                \n",
    "                if(next_word == -1):\n",
    "                    break\n",
    "                \n",
    "                problem_properties.current_length += problem_properties.word_len - problem_properties.common_nucleotides_matrix[problem_properties.current_word, next_word]\n",
    "                problem_properties.avaible_words_number -= 1\n",
    "                problem_properties.avaible_words[next_word]= 0\n",
    "                \n",
    "                \"\"\"print(problem_properties.words[problem_properties.current_word])\n",
    "                print((problem_properties.word_len - problem_properties.common_nucleotides_matrix[problem_properties.current_word, next_word]) * ' ' + problem_properties.words[problem_properties.next_word] + \"\\tPokrywanie na tylu znakach: \" + str(problem_properties.common_nucleotides_matrix[problem_properties.current_word, next_word]))\n",
    "                print(\"Liczba niewykorzystanych jeszcze slow: \" + str(problem_properties.avaible_words_number))\n",
    "                print(\"Obecna dlugosc ciagu: \" + str(problem_properties.current_length))\n",
    "                print(\"\\n\")\"\"\"\n",
    "                \n",
    "                problem_properties.current_word = next_word\n",
    "                sequence.append(problem_properties.current_word)\n",
    "            \n",
    "            #print(\"Koniec tworzenia ciagu.\")\n",
    "            sequences.append(sequence)\n",
    "            \n",
    "        print(\"Wykonano wszystkie sekwencje w obecnej iteracji\")\n",
    "        \"\"\"for i in range(len(sequences)):\n",
    "            print(str(i) + \":\\t\" + str(len(sequences[i])))\"\"\"\n",
    "            \n",
    "        sequences.sort(key = lambda x: len(x), reverse=True)\n",
    "\n",
    "        \"\"\"for i in range(len(sequences)):\n",
    "            print(str(i) + \":\\t\" + str(len(sequences[i])))\"\"\"\n",
    "        \n",
    "        print(sequences[0])\n",
    "        #print(sequences[1])\n",
    "        #nagrodzenie najlepszych rozwiązań\n",
    "        part_of_the_best_sequences = 0.1\n",
    "        amount_of_the_best_sequences = int(attempts_number * part_of_the_best_sequences)\n",
    "        for i in range(amount_of_the_best_sequences):\n",
    "            print(str(i) + \":\\t\" + str(len(sequences[i])))\n",
    "        best_price_for_sequence = 1.2\n",
    "        for iSequence in range(amount_of_the_best_sequences):\n",
    "            sequence = sequences[iSequence]\n",
    "            price_for_sequence = 1 + (best_price_for_sequence - 1) * ((amount_of_the_best_sequences - iSequence) / amount_of_the_best_sequences)\n",
    "            #print(\"price_for_sequence = \" + str(price_for_sequence))\n",
    "            for iConnection in range(len(sequence) - 1):\n",
    "                first_word = sequence[iConnection]\n",
    "                second_word = sequence[iConnection + 1]\n",
    "                \n",
    "                price_for_connection = 1 + (price_for_sequence - 1) * (problem_properties.common_nucleotides_matrix[first_word, second_word] / (problem_properties.word_len - 1))\n",
    "                problem_properties.next_word_power_matrix[first_word, second_word] *= price_for_connection\n",
    "                \n",
    "                \"\"\"#print(str(max_sum) + \" < \" + str(sum_of_probability))\n",
    "                if(max_w_macierzy < problem_properties.next_word_power_matrix[first_word, second_word]):\n",
    "                    max_w_macierzy = problem_properties.next_word_power_matrix[first_word, second_word]\n",
    "                    print(\"max_w_macierzy = \" + str(max_w_macierzy))\n",
    "                    print(\"nagradzalem mnozac przez \" + str(price_for_connection))\n",
    "                    print(\"price_for_sequence = \" + str(price_for_sequence))\"\"\"\n",
    "            \n",
    "            \n",
    "            \"\"\"wyswietlanie mnożnika dla połączeń - im bardziej wyrazy się zazębiają, tym większa liniowo jest wartość mnożnika\n",
    "            for i in range(problem_properties.word_len):\n",
    "                price_for_connection = 1 + (price_for_sequence - 1) * (i / (problem_properties.word_len - 1))\n",
    "                print(\"price_for_connection = \" + str(price_for_connection))\"\"\"\n",
    "    \n",
    "    \n",
    "        #wygładzanie macierzy wag prawdopodobieństwa w celu zapobiegnięcia nadmiernemu zdominowaniu przez najlepsze rozwiązanie\n",
    "        print(\"wykonywanie funkcji compensation_of_next_word_power_matrix...\")\n",
    "        compensation_of_next_word_power_matrix_with_numpy_tricks_2(problem_properties)\n",
    "    \n",
    "    print(\"koniec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr /><hr /><br /><br /><br />\n",
    "<h3>Poniżej można swobodnie testować i sprawdzać działanie wykorzystywanych konstrukcji języka python.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaible_words_number = 0\n",
    "def testF():\n",
    "    print(testVar)\n",
    "    print(\"testVar2 = \" + str(testVar2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVar = 5\n",
    "testF()\n",
    "for i in range(5):\n",
    "    testVar2 = i\n",
    "    testF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(random.uniform(0.9992892359651135, 0.9992892359651136))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPrzekazywanie(x):\n",
    "    x += 10\n",
    "\n",
    "x = 5\n",
    "print(x)\n",
    "testPrzekazywanie(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vartest = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "print(vartest)\n",
    "print(vartest.shape)\n",
    "print(vartest[1])\n",
    "print(max(vartest[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.log(625, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(6)\n",
    "print(x)\n",
    "y = np.zeros((4))\n",
    "print(y)\n",
    "z = np.zeros(13, dtype=int)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "for j in range(1, words_num + 1):\n",
    "    max_common_nucleotides[j] = common_nucleotides_matrix[1, j]\n",
    "    for i in range(2, words_num + 1):\n",
    "        if(max_common_nucleotides[j] < common_nucleotides_matrix[i, j]):\n",
    "            max_common_nucleotides[j] = common_nucleotides_matrix[i, j]\"\"\"\n",
    "\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(x)\n",
    "y = x.max(0)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    for j in range(1, words_num + 1):\n",
    "        next_word_power_matrix[0, j] = wages[ word_len - 1 - max_common_nucleotides[j] ]\"\"\"\n",
    "\n",
    "\n",
    "a = np.array([1, 2, 3, 5, 6])\n",
    "print(a)\n",
    "b = np.array([0, 1, 2, 1, 0])\n",
    "print(b)\n",
    "values = np.array([5, 20, 100])\n",
    "print(values)\n",
    "\n",
    "a = values[2 - b]\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"occurrence_counter = np.zeros(word_len)\n",
    "for j in range(1, words_num + 1):\n",
    "    occurrence_counter[ common_nucleotides_matrix[0, j] ] += 1\"\"\"\n",
    "\n",
    "x = np.array([0, 1,3, 2, 1, 1, 1, 4, 6, 6, 2])\n",
    "y = np.zeros(7, dtype=int)\n",
    "unique, counts = np.unique(x, return_counts=True)\n",
    "y[unique] = counts\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.copy(wages)\n",
    "    for j in range(word_len):\n",
    "        if(occurrence_counter[j] != 0):\n",
    "            current_wages[j] /= occurrence_counter[j]\"\"\"\n",
    "\n",
    "x = np.array([1, 4, 9, 4, 10, 30])\n",
    "y = np.array([1, 2, 3, 0, 2, 5])\n",
    "\n",
    "print(y)\n",
    "y[y == 0] = 1\n",
    "print(y)\n",
    "\n",
    "z = x / y\n",
    "#z = np.where(y != 0, x / y, x)\n",
    "#z = np.where(y != 0, 'a', 'b')\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#waga przyznawana jest na podstawie długości wspólnego sufiksu-prefiksu słowa i-tego i j-tego\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_1_with_numpy_tricks():\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for i in range(1, words_num + 1):\n",
    "        for j in range(1, words_num + 1):\n",
    "            next_word_power_matrix[i, j] = wages[ common_nucleotides_matrix[i, j] ]\"\"\"\n",
    "\n",
    "x = np.zeros((3, 3))\n",
    "print(x)\n",
    "y = np.array([10, 20, 30])\n",
    "print(y)\n",
    "z = np.array([[0, 1, 2], [1, 1, 1], [2, 2, 0]])\n",
    "print(z)\n",
    "x = y[z]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_next_word_power_matrix_2_with_numpy_tricks2():\n",
    "    for i in range(1, words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        occurrence_counter = np.zeros(word_len)\n",
    "        unique, counts = np.unique(common_nucleotides_matrix[i, 1:], return_counts=True)\n",
    "        occurrence_counter[unique] = counts\n",
    "        \n",
    "        #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "        current_wages = np.copy(wages)\n",
    "        occurrence_counter[occurrence_counter == 0] = 1\n",
    "        current_wages /= occurrence_counter\n",
    "        \n",
    "        #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "        next_word_power_matrix[i] = current_wages[ common_nucleotides_matrix[i] ]\"\"\"\n",
    "\n",
    "def my_func(a):\n",
    "    print(\"a = \" + str(a))\n",
    "    return np.unique(a, return_counts=True)\n",
    "\n",
    "x = np.array([[0, 1, 2, 4, 3], [1, 2, 0, 3, 4], [1, 2, 3, 4, 4]])\n",
    "print(x)\n",
    "result = np.apply_along_axis(my_func, axis=1, arr=x)\n",
    "#unique, counts = np.unique(x, return_counts=True, axis=0)\n",
    "print(result)\n",
    "#print(unique)\n",
    "#print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "b = [1, 0, 0, 1, 1]\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((7, 4))\n",
    "ind = [0, 2, 3]\n",
    "for i in range(7):\n",
    "    x[i, ind] = 999\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"current_wages = np.copy(wages)\n",
    "current_wages /= occurrence_counter\"\"\"\n",
    "\n",
    "x = np.zeros((7, 4))\n",
    "y = [0, 2, 3, 10]\n",
    "x[:] = y\n",
    "y[1] = -10\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"next_word_power_matrix[:,:] = current_wages[ind, common_nucleotides_matrix[ind] ]\"\"\"\n",
    "\n",
    "ind = np.arange(3)\n",
    "print(ind)\n",
    "\n",
    "x = np.zeros((3, 3))\n",
    "w = np.array([[10, 20, 30, 40, 50], [100, 200, 300, 400, 500], [1000, 2000, 3000, 4000, 5000]])\n",
    "print(w)\n",
    "\n",
    "c = np.array([[0, 1, 2], [2, 3, 4], [0, 2, 4]])\n",
    "\n",
    "tmp = (0, [0, 1, 2])\n",
    "#x[:, :] = w[ind, c[ind]]     #to jest źle\n",
    "x[:, :] = w[tmp]\n",
    "\n",
    "\n",
    "\"\"\"x[:, :] = w[ind, c]\n",
    "for i in range(3):\n",
    "    x[i] = w[i, c[i]]\"\"\"\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def generate_common_nucleotides_matrix_full_iterating():\n",
    "    for i in range(1, words_num + 1):\n",
    "            for j in range(1, words_num + 1):\n",
    "                if(i != j):\n",
    "                    common_nucleotides_matrix[i, j] = common_nucleotides_max_number_full_iterating(words[i], words[j])\n",
    "                else:\n",
    "                    common_nucleotides_matrix[i, i] = 0\"\"\"\n",
    "\n",
    "def testFunc(a, b):\n",
    "    result = 0\n",
    "    if(a < b):\n",
    "        result = a + 10\n",
    "    else:\n",
    "        result = b - 100\n",
    "    return result\n",
    "\n",
    "x = np.zeros((5, 5))\n",
    "y = np.zeros((5, 5))\n",
    "ind = np.arange(5)\n",
    "\n",
    "x[:] = ind\n",
    "print(x)\n",
    "\n",
    "\n",
    "y = x.transpose()\n",
    "print(y)\n",
    "\n",
    "vTestFunc = np.vectorize(testFunc)\n",
    "result = vTestFunc(x, y)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"min_value = max_value\n",
    "for j in range(1, problem_properties.words_num + 1):\n",
    "    if((problem_properties.next_word_power_matrix[i, j] >= 1) and (min_value > problem_properties.next_word_power_matrix[i, j])):\n",
    "        min_value = problem_properties.next_word_power_matrix[i, j]\"\"\"\n",
    "\n",
    "x = np.array([[2, 3.4, 3, 5, 0.3, -4, 2, 1.2, 1.6, 0.3, -0.1, 0.9],\n",
    "              [4, 3.2, 2, 6, 0.6, -3, 6, 1.7, 1.1, 0.2, -0.5, 0.8]])\n",
    "result = min(x[0, x[0] >= 1])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for j in range(1, problem_properties.words_num + 1):\n",
    "    if(min_value < problem_properties.next_word_power_matrix[i, j]):\n",
    "        problem_properties.next_word_power_matrix[i, j] = min_value * (1 + math.log(problem_properties.next_word_power_matrix[i, j] / min_value, base_of_logarithm))\"\"\"\n",
    "\n",
    "x = np.array([[0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              [-4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16]])\n",
    "print(x)\n",
    "\n",
    "min_value = 5\n",
    "#x[0, x[0] > min_value] = 2 * (1 + x[0, x[0] > min_value])\n",
    "tmp = x[0, x[0] > min_value]\n",
    "x[0, x[0] > min_value] = 2 * (1 + x[0, x[0] > min_value])\n",
    "print(x[0])\n",
    "print(np.log(x[0]) / np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "print(x)\n",
    "y = np.flip(x)\n",
    "y[3] = 999\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "print(x)\n",
    "y = x[::-1]\n",
    "y[3] = 999\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range(problem_properties.words_num + 1):\n",
    "    max_value = max(problem_properties.next_word_power_matrix[i])\n",
    "    sum_value = sum(problem_properties.next_word_power_matrix[i])\"\"\"\n",
    "\n",
    "x = np.array([[1, 2, 5], \n",
    "              [4, 7, 3]])\n",
    "\n",
    "max_value = np.max(x, axis=1)\n",
    "print(max_value)\n",
    "\n",
    "sum_value = np.sum(x, axis=1)\n",
    "print(sum_value)\n",
    "\n",
    "print(max_value > sum_value * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range(problem_properties.words_num + 1):\n",
    "    if(max_value > sum_value * compensation_coef):\n",
    "        #poszukiwanie minimalnej wartości wagi prawdopodobieństwa nie mniejszej niż wartość 1. Wartość ta jest potrzebna do wzoru wygładzającego\n",
    "        min_value = min(problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] >= 1])\n",
    "\n",
    "        #wygładzanie wag większych niż wartość 1\n",
    "        problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] > min_value] = min_value * (1 + np.log(problem_properties.next_word_power_matrix[i, problem_properties.next_word_power_matrix[i] > min_value] / min_value) / np.log(base_of_logarithm))\"\"\"\n",
    "\n",
    "x = np.array([[1, 2, 5], \n",
    "              [4, 7, 3], \n",
    "              [1, 10, 4], \n",
    "              [6, 7, 8]])\n",
    "\n",
    "max_value = np.max(x, axis=1)\n",
    "print(max_value)\n",
    "max_value_matrix = np.zeros((3, 4))\n",
    "max_value_matrix[:] = max_value\n",
    "max_value_matrix = max_value_matrix.transpose()\n",
    "print(max_value_matrix)\n",
    "\n",
    "sum_value = np.sum(x, axis=1)\n",
    "print(sum_value)\n",
    "sum_value_matrix = np.zeros((3, 4))\n",
    "sum_value_matrix[:] = sum_value\n",
    "sum_value_matrix = sum_value_matrix.transpose()\n",
    "print(sum_value_matrix)\n",
    "\n",
    "mask_row = max_value_matrix > sum_value_matrix * 0.6\n",
    "print(mask_row)\n",
    "\n",
    "tmpx = np.copy(x)\n",
    "print(\"\\ntmpx przed:\\n\" + str(tmpx))\n",
    "wsk = tmpx < 3\n",
    "tmpx[wsk] = max_value_matrix[wsk]\n",
    "print(\"\\ntmpx po:\\n\" + str(tmpx))\n",
    "\n",
    "min_value = np.min(tmpx, axis=1)\n",
    "print(min_value)\n",
    "min_value_matrix = np.zeros((3, 4))\n",
    "min_value_matrix[:] = min_value\n",
    "min_value_matrix = min_value_matrix.transpose()\n",
    "print(min_value_matrix)\n",
    "\n",
    "mask_final = ((x >= min_value_matrix) * (mask_row))\n",
    "print(mask_final)\n",
    "\n",
    "print(\"\\nx przed:\\n\" + str(x))\n",
    "x[mask_final] = min_value_matrix[mask_final] * (1 + x[mask_final])\n",
    "print(\"\\nx po:\\n\" + str(x))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
