{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "import re\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_PATH = path.dirname(path.abspath(\"__file__\"))  # gdyby nie działało, usuń cudzysłów\n",
    "INSTANCES_PATH = path.join(BASE_DIR_PATH, \"instances\")\n",
    "NEGATIVE_RANDOM_PATH = path.join(INSTANCES_PATH, \"negative_random\")\n",
    "NEGATIVE_REPETITIONS_PATH = path.join(INSTANCES_PATH, \"negative_repetitions\")\n",
    "POSITIVE_END_ERRORS_PATH = path.join(INSTANCES_PATH, \"positive_end_errors\")\n",
    "POSITIVE_RANDOM_PATH = path.join(INSTANCES_PATH, \"positive_random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_random_filenames = [path.join(NEGATIVE_RANDOM_PATH, f) for f in listdir(NEGATIVE_RANDOM_PATH) if path.isfile(path.join(NEGATIVE_RANDOM_PATH, f))]\n",
    "negative_repetitions_filenames = [path.join(NEGATIVE_REPETITIONS_PATH, f) for f in listdir(NEGATIVE_REPETITIONS_PATH) if path.isfile(path.join(NEGATIVE_REPETITIONS_PATH, f))]\n",
    "positive_end_errors_filenames = [path.join(POSITIVE_END_ERRORS_PATH, f) for f in listdir(POSITIVE_END_ERRORS_PATH) if path.isfile(path.join(POSITIVE_END_ERRORS_PATH, f))]\n",
    "positive_random_filenames = [path.join(POSITIVE_RANDOM_PATH, f) for f in listdir(POSITIVE_RANDOM_PATH) if path.isfile(path.join(POSITIVE_RANDOM_PATH, f))]\n",
    "\n",
    "selected_filenames = negative_random_filenames + negative_repetitions_filenames + positive_end_errors_filenames + positive_random_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in selected_filenames:\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "        \n",
    "        words = file.read().splitlines()\n",
    "        \n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        \n",
    "        print(\"nazwa pliku: \" + inst_name)\n",
    "        print(\"długość słowa: \" + str(word_len))\n",
    "        print(\"oryginalna liczba słów: \" + str(org_words_num))\n",
    "        print(\"oryginalna długość sekwencji: \"+ str(org_seq_len))\n",
    "        print(\"liczba błędów negatywnych: \" + str(neg_errors_number))\n",
    "        print(\"liczba błędów pozytywnych: \" + str(pos_errors_number))\n",
    "        print(words[:5])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#funkcja zwraca maksymalną liczbę nukleotydów, na których zazębia się sufiks nucl1 z prefiksem nucl2\n",
    "#poszukiwanie poprzez coraz to mniejszą długość ciągu, porównywanie ciągów znak po znaku\n",
    "def common_nucleotides_max_number_full_iterating(nucl1, nucl2):\n",
    "    word_len = len(nucl1)\n",
    "    result = word_len - 1       #zmienna zawierająca końcowy wynik\n",
    "    \n",
    "    while(result > 0):          #badanie coraz to mniejszej możliwej długości wspólnego ciągu\n",
    "        i1 = word_len - result\n",
    "        i2 = 0\n",
    "        \n",
    "        while(i1 < word_len):              #porównanie nachodzących końcówek, znak po znaku\n",
    "            if(nucl1[i1] != nucl2[i2]):    #znaki się nie zgadzają\n",
    "                break\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "        \n",
    "        if(i1 == word_len):    #porównywanie ciągów zostało wykonane pozytywnie po wszystkich znakach\n",
    "            break\n",
    "        \n",
    "        result -= 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "#funkcja zwraca maksymalną liczbę nukleotydów, na których zazębia się sufiks nucl1 z prefiksem nucl2\n",
    "#poszukiwanie poprzez coraz to mniejszą długość ciągu, bezpośrednie porównywanie ciągów przy pomocy mechanizmu \"slicing\"\n",
    "def common_nucleotides_max_number_iterating_with_slicing(nucl1, nucl2):\n",
    "    word_len = len(nucl1)\n",
    "    result = word_len - 1       #zmienna zawierająca końcowy wynik\n",
    "    \n",
    "    while(result > 0):          #badanie coraz to mniejszej możliwej długości wspólnego ciągu\n",
    "        i1 = word_len - result\n",
    "        i2 = 0\n",
    "        \n",
    "        if(nucl1[-result:] == nucl2[:result]): #porównywanie ciągów przy pomocy mechanizmu \"slicing\"\n",
    "            break\n",
    "        \n",
    "        result -= 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Testowanie szybkości wyznaczania wspólego sufiksu nucl1 z prefiksem nucl2 ----------------#\n",
    "def speed_test_common_nucleotides_max_number(function, repetition):\n",
    "    print(\"Function testing in progress...\")\n",
    "    start_time = time.time()\n",
    "    filename = negative_random_filenames[0]\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "        \n",
    "        while(repetition > 0):\n",
    "            for i in range(words_num):\n",
    "                for j in range(words_num):\n",
    "                    if(i != j):\n",
    "                        number = function(words[i], words[j])\n",
    "            repetition -= 1\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"End of the function testing.\")\n",
    "    print(\"Time: \" + str(elapsed_time) + \"\\n\")\n",
    "\n",
    "#Wywołanie testowania funkcji\n",
    "#speed_test_common_nucleotides_max_number(common_nucleotides_max_number_full_iterating, 10)            #repetition=10 Time: 13.98816466331482\n",
    "#speed_test_common_nucleotides_max_number(common_nucleotides_max_number_iterating_with_slicing, 10)    #repetition=10 Time: 16.22281813621521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_starting_wages(n, k):\n",
    "    result = np.zeros((n))\n",
    "    n -= 1\n",
    "    result[n] = 1.0\n",
    "    while(n > 0):\n",
    "        n -= 1\n",
    "        result[n] = result[n + 1] / k\n",
    "    \n",
    "    return result\n",
    "\n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#waga przyznawana jest na podstawie długości wspólnego sufiksu-prefiksu słowa i-tego i j-tego\n",
    "def generate_next_word_power_matrix_1():\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for i in range(1, words_num + 1):\n",
    "        for j in range(1, words_num + 1):\n",
    "            next_word_power_matrix[i, j] = wages[ common_nucleotides_matrix[i, j] ]\n",
    "\n",
    "#funkcja oblicza początkowe wagi prawdopodobieństwa dla wyboru j-tego wyrazu po dokonaniu już wyboru i-tego\n",
    "#określona już waga prawdopodobieństwa dla połączenia wyrazów o pewnej długości zazębiających się końcówek jest równomiernie rozdzielana na wsystkie połączenia o tejże długości wspólnego ciągu\n",
    "def generate_next_word_power_matrix_2():\n",
    "    for i in range(1, words_num + 1):\n",
    "        #zliczenie wystąpień zachodzenia wyrazów na danej liczbie znaków\n",
    "        occurrence_counter = np.zeros(word_len)\n",
    "        for j in range(1, words_num + 1):\n",
    "            occurrence_counter[ common_nucleotides_matrix[i, j] ] += 1\n",
    "        \n",
    "        #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "        current_wages = np.copy(wages)\n",
    "        for j in range(word_len):\n",
    "            if(occurrence_counter[j] != 0):\n",
    "                current_wages[j] /= occurrence_counter[j]\n",
    "        \n",
    "        #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "        for j in range(1, words_num + 1):\n",
    "            next_word_power_matrix[i, j] = current_wages[ common_nucleotides_matrix[i, j] ]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<h2>Wyznaczenie wag prawdopodobieństwa dla wyboru wyrazu rozpoczynającego sekwencje</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja ustawia równe szanse wyboru słowa rozpoczynającego sekwencje\n",
    "def generate_chance_for_first_word():\n",
    "    next_word_power_matrix[0, 1:] = 1;\n",
    "\n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "def generate_chance_for_first_word_1_full_iterating():\n",
    "    max_common_nucleotides = np.zeros(words_num + 1, dtype=int)\n",
    "\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    for j in range(1, words_num + 1):\n",
    "        max_common_nucleotides[j] = common_nucleotides_matrix[1, j]\n",
    "        for i in range(2, words_num + 1):\n",
    "            if(max_common_nucleotides[j] < common_nucleotides_matrix[i, j]):\n",
    "                max_common_nucleotides[j] = common_nucleotides_matrix[i, j]\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    for j in range(1, words_num + 1):\n",
    "        next_word_power_matrix[0, j] = wages[ word_len - 1 - max_common_nucleotides[j] ]\n",
    "\n",
    "        \n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_chance_for_first_word_1_with_numpy_tricks():\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    max_common_nucleotides = common_nucleotides_matrix.max(0)\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    next_word_power_matrix[0] = wages[ word_len - 1 - max_common_nucleotides]\n",
    "    \n",
    "    \n",
    "\n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#określona już waga jest równomiernie rozdzielona na wyrazy o poszczególnej długości maksymalnego zazębienia\n",
    "def generate_chance_for_first_word_2_full_iterating():\n",
    "    max_common_nucleotides = np.zeros(words_num + 1, dtype=int)\n",
    "\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    for j in range(1, words_num + 1):\n",
    "        max_common_nucleotides[j] = common_nucleotides_matrix[1, j]\n",
    "        for i in range(2, words_num + 1):\n",
    "            if(max_common_nucleotides[j] < common_nucleotides_matrix[i, j]):\n",
    "                max_common_nucleotides[j] = common_nucleotides_matrix[i, j]\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag, waga jest równomiernie rozdizelona\n",
    "    occurrence_counter = np.zeros(word_len)\n",
    "    for j in range(1, words_num + 1):\n",
    "        occurrence_counter[ common_nucleotides_matrix[0, j] ] += 1\n",
    "\n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.copy(wages)\n",
    "    for j in range(word_len):\n",
    "        if(occurrence_counter[j] != 0):\n",
    "            current_wages[j] /= occurrence_counter[j]\n",
    "\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    for j in range(1, words_num + 1):\n",
    "        next_word_power_matrix[0, j] = current_wages[ word_len - 1 - max_common_nucleotides[j] ]\n",
    "        \n",
    "        \n",
    "#funkcja ustawia większe szanse wyboru słowa dla wyrazów, których prefiks w maksymalnym przypadku pokrywa się na jaknajmniejszej ilości zanków z jakim kolwiek sufiksem\n",
    "#określona już waga jest równomiernie rozdzielona na wyrazy o poszczególnej długości maksymalnego zazębienia\n",
    "#szybsza wersja wykorzystująca możliwości biblioteki numpy\n",
    "def generate_chance_for_first_word_2_with_numpy_tricks():\n",
    "    #wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "    max_common_nucleotides = common_nucleotides_matrix.max(0)\n",
    "    \n",
    "    #przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag, waga jest równomiernie rozdizelona\n",
    "    occurrence_counter = np.zeros(word_len)\n",
    "    unique, counts = np.unique(common_nucleotides_matrix[0, 1:], return_counts=True)\n",
    "    occurrence_counter[unique] = counts\n",
    "\n",
    "    #obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.copy(wages)\n",
    "    occurrence_counter[occurrence_counter == 0] = 1\n",
    "    current_wages /= occurrence_counter\n",
    "\n",
    "    #przydzielenia wag dla konkretnych połączeń wyrazów\n",
    "    next_word_power_matrix[0] = current_wages[ word_len - 1 - max_common_nucleotides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Testowanie szybkości wyznaczania wag prawdopodobień dla wyboru pierwszego wyrazu w sekwencji ----------------#\n",
    "def speed_test_generate_chance_for_first_word(function, repetition):\n",
    "    print(\"Preparing required variables...\")\n",
    "    filename = negative_random_filenames[0]\n",
    "    with open(filename, 'r') as file:\n",
    "        inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "        words = file.read().splitlines()\n",
    "\n",
    "        word_len = len(words[0])\n",
    "        org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "        org_seq_len = org_words_num + word_len - 1\n",
    "        neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "        neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "        pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "        pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "        words_num = len(words)\n",
    "\n",
    "        #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "        words = [\"Poczatek\"] + words\n",
    "\n",
    "\n",
    "        #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "        common_nucleotides_matrix = np.zeros((words_num + 1, words_num + 1), dtype=int)\n",
    "        for i in range(1, words_num + 1):\n",
    "            for j in range(1, words_num + 1):\n",
    "                if(i != j):\n",
    "                    number = common_nucleotides_max_number_full_iterating(words[i], words[j])\n",
    "                    common_nucleotides_matrix[i, j] = number\n",
    "                else:\n",
    "                    common_nucleotides_matrix[i, i] = 0\n",
    "\n",
    "        wages = set_starting_wages(word_len, 2)\n",
    "\n",
    "\n",
    "        next_word_power_matrix = np.zeros((words_num + 1, words_num + 1))\n",
    "        generate_next_word_power_matrix_2()\n",
    "        \n",
    "        \n",
    "        print(\"Function testing in progress...\")\n",
    "        start_time = time.time()\n",
    "        while(repetition > 0):\n",
    "            function()\n",
    "            repetition -= 1\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"End of the function testing.\")\n",
    "        print(\"Time: \" + str(elapsed_time) + \"\\n\\n\")\n",
    "\n",
    "#Wywołanie testowania funkcji\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word, 100)                   #repetition=100 Time: 0.0\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word_1_full_iterating, 100)    #repetition=100 Time: 7.25950026512146\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word_2_full_iterating, 100)    #repetition=100 Time: 7.367282152175903\n",
    "#speed_test_generate_chance_for_first_word(generate_chance_for_first_word_1_with_numpy_tricks, 100) #repetition=100 Time: 0.020961999893188477\n",
    "speed_test_generate_chance_for_first_word(generate_chance_for_first_word_2_with_numpy_tricks, 100)  #repetition=100 Time: 0.026450395584106445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Sprawdzanie poprawności wyznaczania wag prawdopodobień dla wyboru pierwszego wyrazu w sekwencji ----------------#\n",
    "print(\"Preparing required variables...\")\n",
    "filename = negative_random_filenames[0]\n",
    "with open(filename, 'r') as file:\n",
    "    inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "    word_len = len(words[0])\n",
    "    org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "    org_seq_len = org_words_num + word_len - 1\n",
    "    neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "    neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "    pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "    pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "    words_num = len(words)\n",
    "\n",
    "    #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "    words = [\"Poczatek\"] + words\n",
    "\n",
    "\n",
    "    #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "    common_nucleotides_matrix = np.zeros((words_num + 1, words_num + 1), dtype=int)\n",
    "    for i in range(1, words_num + 1):\n",
    "        for j in range(1, words_num + 1):\n",
    "            if(i != j):\n",
    "                number = common_nucleotides_max_number_full_iterating(words[i], words[j])\n",
    "                common_nucleotides_matrix[i, j] = number\n",
    "            else:\n",
    "                common_nucleotides_matrix[i, i] = 0\n",
    "\n",
    "    wages = set_starting_wages(word_len, 2)\n",
    "\n",
    "\n",
    "    next_word_power_matrix = np.zeros((words_num + 1, words_num + 1))\n",
    "    generate_next_word_power_matrix_2()\n",
    "\n",
    "\n",
    "    print(\"Function testing in progress...\")\n",
    "    #generate_chance_for_first_word_1_full_iterating()\n",
    "    generate_chance_for_first_word_2_full_iterating()\n",
    "    vector1 = np.copy(next_word_power_matrix[0])\n",
    "    #generate_chance_for_first_word_1_with_numpy_tricks()\n",
    "    generate_chance_for_first_word_2_with_numpy_tricks()\n",
    "    vector2 = np.copy(next_word_power_matrix[0])\n",
    "    \n",
    "    print(vector2 - vector1)\n",
    "\n",
    "\n",
    "    print(\"End of the function testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zmienne\n",
    "avaible_words_number = 0\n",
    "#max_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja wybiera kolejny wyraz dla tworzonego ciągu\n",
    "def choose_next_word():\n",
    "    global avaible_words_number\n",
    "    #global max_sum\n",
    "    #print(\"avaible words przed: \" + str(avaible_words_number))\n",
    "    #wybranie odpowiednich wektorów z macierzy, które przechowują dane dla ostatnio wybranego słowa\n",
    "    common_nucleotides_vector = common_nucleotides_matrix[current_word]\n",
    "    next_word_power_vector = next_word_power_matrix[current_word]\n",
    "    \n",
    "    #jeśli obecna długość wynikowego ciągu zwiększona o pełną długość kolejnego słowa przekracza ograniczającą długość ciągu znaków,\n",
    "    #to trzeba wykluczyć możliwość wyboru kolejnego słowa, które by to za bardzo zwiększyła długość wynikowej sekwencji\n",
    "    #print(str(current_length) + \" + \" + str(word_len) + \" > \" + str(org_seq_len))\n",
    "    if(current_length + word_len > org_seq_len):\n",
    "        for j in range(1, words_num + 1):\n",
    "            if((avaible_words[j]) and (current_length + (word_len - common_nucleotides_vector[j]) > org_seq_len)):\n",
    "                avaible_words[j] = 0\n",
    "                avaible_words_number -= 1\n",
    "        \n",
    "        #print(\"Juz prawie koniec - mozna dopasowac jeszcze \" + str(avaible_words_number) + \" slow\")\n",
    "    \n",
    "    #nie ma już dostępnych słów do doklejenia\n",
    "    if(not(avaible_words_number)):\n",
    "        return -1\n",
    "    \n",
    "    #obliczenie sumy mocy prawdopodobieństwa wyboru dla dostępnych słów\n",
    "    sum_of_probability = 0\n",
    "    for j in range(1, words_num + 1):\n",
    "        if(avaible_words[j]):\n",
    "            sum_of_probability += next_word_power_vector[j]\n",
    "\n",
    "            \n",
    "    \"\"\"#print(str(max_sum) + \" < \" + str(sum_of_probability))\n",
    "    if(max_sum < sum_of_probability):\n",
    "        max_sum = sum_of_probability\n",
    "        print(\"sum_of_probability = \" + str(sum_of_probability))\"\"\"\n",
    "    \n",
    "    #realizacja wyboru zgodnie z gęstością prawdopodobieństwa - wybór punktu na odcinku złożonego z sumy mocy prawdopodobieństwa dostępnych połączeń\n",
    "    point_in_range_of_sum_of_probability = random.uniform(0, sum_of_probability)\n",
    "    \n",
    "    #odnalezienie wybranego kolejnego słowa, które zostało wskazane przez wylosowany punkt na odcinku\n",
    "    j = 1\n",
    "    while(not(avaible_words[j])):\n",
    "        j += 1\n",
    "    \n",
    "    current_sum_of_probability = next_word_power_vector[j]\n",
    "    while(point_in_range_of_sum_of_probability > current_sum_of_probability):\n",
    "        j += 1\n",
    "        while(not(avaible_words[j])):\n",
    "            j += 1\n",
    "        current_sum_of_probability += next_word_power_vector[j]\n",
    "    \n",
    "    #print(\"avaible words po: \" + str(avaible_words_number))\n",
    "    \n",
    "    return j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja dokonuje wygładzania wartości wag prawdopodobieństw -> zmienia szanse wyboru na bardziej równe, zachowująć jednocześnie porządek preferencji\n",
    "def compensation_of_next_word_power_matrix():\n",
    "    compensation_coef = 0.98\n",
    "    base_of_logarithm = 2\n",
    "    \n",
    "    for i in range(words_num + 1):\n",
    "        max_value = max(next_word_power_matrix[i])\n",
    "        sum_value = sum(next_word_power_matrix[i])\n",
    "        \n",
    "        #jeśli maksymalna wartość zdecydowanie się wyróżnia, to należy złagodzić dysproporcje między wagami prawdopodobieństw\n",
    "        if(max_value > sum_value * compensation_coef):\n",
    "            \n",
    "            #poszukiwanie minimalnej wartości wagi prawdopodobieństwa nie mniejszej niż wartość 1. Wartość ta jest potrzebna do wzoru wygładzającego\n",
    "            min_value = max_value\n",
    "            for j in range(1, words_num + 1):\n",
    "                if((next_word_power_matrix[i, j] >= 1) and (min_value > next_word_power_matrix[i, j])):\n",
    "                    min_value = next_word_power_matrix[i, j]\n",
    "            \n",
    "            #wygładzanie wag większych niż wartość 1\n",
    "            for j in range(1, words_num + 1):\n",
    "                if(min_value < next_word_power_matrix[i, j]):\n",
    "                    next_word_power_matrix[i, j] = min_value * (1 + math.log(next_word_power_matrix[i, j] / min_value, base_of_logarithm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<h1>Główny kod wykonujący obliczenia zgodnie z algorytmem mrówkowym</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = negative_random_filenames[0]\n",
    "with open(filename, 'r') as file:\n",
    "    inst_name = filename[filename.rfind('/') + 1:]\n",
    "\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "    word_len = len(words[0])\n",
    "    org_words_num = int(re.search('(?<=\\.)[0-9]+', inst_name).group(0))\n",
    "    org_seq_len = org_words_num + word_len - 1\n",
    "    neg_errors_number = re.search('(?<=\\-)[0-9]+', inst_name)\n",
    "    neg_errors_number = int(neg_errors_number.group(0)) if neg_errors_number else 0\n",
    "    pos_errors_number = re.search('(?<=\\+)[0-9]+', inst_name)\n",
    "    pos_errors_number = int(pos_errors_number.group(0)) if pos_errors_number else 0\n",
    "    words_num = len(words)\n",
    "\n",
    "    print(\"nazwa pliku: \" + inst_name)\n",
    "    print(\"długość słowa: \" + str(word_len))\n",
    "    print(\"oryginalna liczba słów: \" + str(org_words_num))\n",
    "    print(\"oryginalna długość sekwencji: \"+ str(org_seq_len))\n",
    "    print(\"liczba błędów negatywnych: \" + str(neg_errors_number))\n",
    "    print(\"liczba błędów pozytywnych: \" + str(pos_errors_number))\n",
    "    print(\"liczba oligonukleotydów: \" + str(words_num))\n",
    "    \n",
    "    #dodanie pozornego słowa w celu zaimplementowania sytuacji wyboru pierwszego wyrazu rozpoczynającego sekwencję\n",
    "    words = [\"Poczatek\"] + words\n",
    "    print(words[:5])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    #wyznaczenie macierzy mówiącej o długości wspólnego i-tego sufiksu z j-tym prefiksem\n",
    "    print(\"common_nucleotides_matrix\")\n",
    "    common_nucleotides_matrix = np.zeros((words_num + 1, words_num + 1), dtype=int)\n",
    "    for i in range(1, words_num + 1):\n",
    "        for j in range(1, words_num + 1):\n",
    "            if(i != j):\n",
    "                number = common_nucleotides_max_number_full_iterating(words[i], words[j])\n",
    "                #print(words[0])\n",
    "                #print((word_len - number) * ' ' + words[i] + \"\\tnumber=\" + str(number) + \"\\n\")\n",
    "                common_nucleotides_matrix[i, j] = number\n",
    "            else:\n",
    "                common_nucleotides_matrix[i, i] = 0\n",
    "    #print(common_nucleotides_matrix[0, :])\n",
    "    \n",
    "    print(\"set_starting_wages()\")\n",
    "    wages = set_starting_wages(word_len, 2)\n",
    "    #print(wages)\n",
    "    \n",
    "    \n",
    "    #wyznaczanie macierzy mocy prawdopodobieństwa następienia j-tego wyrazu po i-tym\n",
    "    next_word_power_matrix = np.zeros((words_num + 1, words_num + 1))\n",
    "    print(\"generate_next_word_power_matrix_1()\")\n",
    "    generate_next_word_power_matrix_1()\n",
    "    #print(\"generate_next_word_power_matrix_2()\")\n",
    "    #generate_next_word_power_matrix_2()\n",
    "    \n",
    "    #ustawienie wag prawdopodobieństwa dla rozpoczęcia tworzenia sekwencji przez dany wyraz\n",
    "    #print(\"generate_chance_for_first_word()\")\n",
    "    #generate_chance_for_first_word()\n",
    "    print(\"generate_chance_for_first_word_1_with_numpy_tricks()\")\n",
    "    generate_chance_for_first_word_1_with_numpy_tricks()\n",
    "    #print(\"generate_chance_for_first_word_2_with_numpy_tricks()\")\n",
    "    #generate_chance_for_first_word_2_with_numpy_tricks()\n",
    "    \n",
    "    \n",
    "    iterations_number = 100    #definicja zmiennej określającej ile iteracji będzie trwał algorytm mrówkowy\n",
    "    #max_w_macierzy = 0\n",
    "    \n",
    "    #wykonywanie poszczególnej iteracji; wykonywanie pętli tyle razy, ile jest zadeklarowanych iteracji do wykonania\n",
    "    for indeks_of_iteration in range(iterations_number):\n",
    "        attempts_number = 100  #definicja zmiennej określającej ile razy dokonywane jest budowanie sekwencji w jednej iteracji\n",
    "        sequences = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        #tworzenie wynikowej sekwencji; powtarzanie prób uzyskania rozwiązania tyle razy, ile jest to określone parametrem 'attempts_number'\n",
    "        print(\"\\nIteracja \" + str(indeks_of_iteration) + \":\\t\\nTrwa wykonywanie wszystkich \" + str(attempts_number) + \" prób utworzenia wynikowej sekwencji.\")\n",
    "        for indeks_of_attempt in range(attempts_number):\n",
    "            current_length = 0                         #definicja zmiennej zawierającej długość utworzonej dotychczas sekwencji\n",
    "            avaible_words_number = words_num           #definicja zmiennej zawierającej liczbę niewykorzystanych jeszcze wyrazów\n",
    "            avaible_words = np.ones((words_num + 1))   #definicja wektora określającego, czy i-ty wyraz jest dostępny\n",
    "            sequence = []\n",
    "            \n",
    "            avaible_words[0] = 0        #odznaczenie użycia już zerowego słowa ('X')\n",
    "            current_word = 0            #definicja zmiennej wskazującej ostatnio wybranego słowa -> słowo zerowe, czyli zaczynane jest tworzenie sekwencji\n",
    "            sequence.append(current_word)\n",
    "            \n",
    "            #nieustannie wykonująca się pętla - zostanie przerwana, gdy nie będzie już możliwości doczepienia słowa przy ograniczeniu ilości znaków w wynikowym ciągu\n",
    "            while(True):\n",
    "                next_word = choose_next_word()\n",
    "                #print(\"Wybrane slowo: \" + str(next_word))\n",
    "                \n",
    "                if(next_word == -1):\n",
    "                    break\n",
    "                \n",
    "                current_length += word_len - common_nucleotides_matrix[current_word, next_word]\n",
    "                avaible_words_number -= 1\n",
    "                avaible_words[next_word]= 0\n",
    "                \n",
    "                \"\"\"print(words[current_word])\n",
    "                print((word_len - common_nucleotides_matrix[current_word, next_word]) * ' ' + words[next_word] + \"\\tPokrywanie na tylu znakach: \" + str(common_nucleotides_matrix[current_word, next_word]))\n",
    "                print(\"Liczba niewykorzystanych jeszcze slow: \" + str(avaible_words_number))\n",
    "                print(\"Obecna dlugosc ciagu: \" + str(current_length))\n",
    "                print(\"\\n\")\"\"\"\n",
    "                \n",
    "                current_word = next_word\n",
    "                sequence.append(current_word)\n",
    "            \n",
    "            #print(\"Koniec tworzenia ciagu.\")\n",
    "            sequences.append(sequence)\n",
    "            \n",
    "        print(\"Wykonano wszystkie sekwencje w obecnej iteracji\")\n",
    "        \"\"\"for i in range(len(sequences)):\n",
    "            print(str(i) + \":\\t\" + str(len(sequences[i])))\"\"\"\n",
    "            \n",
    "        sequences.sort(key = lambda x: len(x), reverse=True)\n",
    "\n",
    "        \"\"\"for i in range(len(sequences)):\n",
    "            print(str(i) + \":\\t\" + str(len(sequences[i])))\"\"\"\n",
    "        \n",
    "        #print(sequences[0])\n",
    "        #print(sequences[1])\n",
    "        #nagrodzenie najlepszych rozwiązań\n",
    "        part_of_the_best_sequences = 0.1\n",
    "        amount_of_the_best_sequences = int(attempts_number * part_of_the_best_sequences)\n",
    "        for i in range(amount_of_the_best_sequences):\n",
    "            print(str(i) + \":\\t\" + str(len(sequences[i])))\n",
    "        best_price_for_sequence = 1.2\n",
    "        for iSequence in range(amount_of_the_best_sequences):\n",
    "            sequence = sequences[iSequence]\n",
    "            price_for_sequence = 1 + (best_price_for_sequence - 1) * ((amount_of_the_best_sequences - iSequence) / amount_of_the_best_sequences)\n",
    "            #print(\"price_for_sequence = \" + str(price_for_sequence))\n",
    "            for iConnection in range(len(sequence) - 1):\n",
    "                first_word = sequence[iConnection]\n",
    "                second_word = sequence[iConnection + 1]\n",
    "                \n",
    "                price_for_connection = 1 + (price_for_sequence - 1) * (common_nucleotides_matrix[first_word, second_word] / (word_len - 1))\n",
    "                next_word_power_matrix[first_word, second_word] *= price_for_connection\n",
    "                \n",
    "                \"\"\"#print(str(max_sum) + \" < \" + str(sum_of_probability))\n",
    "                if(max_w_macierzy < next_word_power_matrix[first_word, second_word]):\n",
    "                    max_w_macierzy = next_word_power_matrix[first_word, second_word]\n",
    "                    print(\"max_w_macierzy = \" + str(max_w_macierzy))\n",
    "                    print(\"nagradzalem mnozac przez \" + str(price_for_connection))\n",
    "                    print(\"price_for_sequence = \" + str(price_for_sequence))\"\"\"\n",
    "            \n",
    "            \n",
    "            \"\"\"wyswietlanie mnożnika dla połączeń - im bardziej wyrazy się zazębiają, tym większa liniowo jest wartość mnożnika\n",
    "            for i in range(word_len):\n",
    "                price_for_connection = 1 + (price_for_sequence - 1) * (i / (word_len - 1))\n",
    "                print(\"price_for_connection = \" + str(price_for_connection))\"\"\"\n",
    "    \n",
    "    \n",
    "        #wygładzanie macierzy wag prawdopodobieństwa w celu zapobiegnięcia nadmiernemu zdominowaniu przez najlepsze rozwiązanie\n",
    "        print(\"wykonywanie funkcji compensation_of_next_word_power_matrix...\")\n",
    "        compensation_of_next_word_power_matrix()\n",
    "    \n",
    "    print(\"koniec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr /><hr /><br /><br /><br />\n",
    "<h3>Poniżej można swobodnie testować i sprawdzać działanie wykorzystywanych konstrukcji języka python.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaible_words_number = 0\n",
    "def testF():\n",
    "    print(testVar)\n",
    "    print(\"testVar2 = \" + str(testVar2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVar = 5\n",
    "testF()\n",
    "for i in range(5):\n",
    "    testVar2 = i\n",
    "    testF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(random.uniform(0.9992892359651135, 0.9992892359651136))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPrzekazywanie(x):\n",
    "    x += 10\n",
    "\n",
    "x = 5\n",
    "print(x)\n",
    "testPrzekazywanie(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vartest = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "print(vartest)\n",
    "print(vartest.shape)\n",
    "print(vartest[1])\n",
    "print(max(vartest[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.log(625, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(6)\n",
    "print(x)\n",
    "y = np.zeros((4))\n",
    "print(y)\n",
    "z = np.zeros(13, dtype=int)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#wyznaczenie maksymalnej długości zazębiającego się prefiksu j-tego wyrazu\n",
    "for j in range(1, words_num + 1):\n",
    "    max_common_nucleotides[j] = common_nucleotides_matrix[1, j]\n",
    "    for i in range(2, words_num + 1):\n",
    "        if(max_common_nucleotides[j] < common_nucleotides_matrix[i, j]):\n",
    "            max_common_nucleotides[j] = common_nucleotides_matrix[i, j]\"\"\"\n",
    "\n",
    "x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(x)\n",
    "y = x.max(0)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#przyznanie wagi prawdopodobieństwa przy użyciu ustalonych wag\n",
    "    for j in range(1, words_num + 1):\n",
    "        next_word_power_matrix[0, j] = wages[ word_len - 1 - max_common_nucleotides[j] ]\"\"\"\n",
    "\n",
    "\n",
    "a = np.array([1, 2, 3, 5, 6])\n",
    "print(a)\n",
    "b = np.array([0, 1, 2, 1, 0])\n",
    "print(b)\n",
    "values = np.array([5, 20, 100])\n",
    "print(values)\n",
    "\n",
    "a = values[2 - b]\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"occurrence_counter = np.zeros(word_len)\n",
    "for j in range(1, words_num + 1):\n",
    "    occurrence_counter[ common_nucleotides_matrix[0, j] ] += 1\"\"\"\n",
    "\n",
    "x = np.array([0, 1,3, 2, 1, 1, 1, 4, 6, 6, 2])\n",
    "y = np.zeros(7, dtype=int)\n",
    "unique, counts = np.unique(x, return_counts=True)\n",
    "y[unique] = counts\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#obliczenie wartości wag prawdopodobieństwa obowiązujących dla danego i-tego wiersza -> dla poszukiwania kolejnego wyrazu po i-tym wyrazie\n",
    "    current_wages = np.copy(wages)\n",
    "    for j in range(word_len):\n",
    "        if(occurrence_counter[j] != 0):\n",
    "            current_wages[j] /= occurrence_counter[j]\"\"\"\n",
    "\n",
    "x = np.array([1, 4, 9, 4, 10, 30])\n",
    "y = np.array([1, 2, 3, 0, 2, 5])\n",
    "\n",
    "print(y)\n",
    "y[y == 0] = 1\n",
    "print(y)\n",
    "\n",
    "z = x / y\n",
    "#z = np.where(y != 0, x / y, x)\n",
    "#z = np.where(y != 0, 'a', 'b')\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
